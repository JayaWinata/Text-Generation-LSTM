{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Embedding, LSTM\n",
    "from keras.utils import to_categorical\n",
    "from pickle import dump, load\n",
    "import numpy as np\n",
    "import PyPDF2\n",
    "import random\n",
    "import spacy\n",
    "import keras\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open and Convert PDF File to Python String"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('neural network.pdf', 'rb')\n",
    "pdf_reader = PyPDF2.PdfReader(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " \n",
      "      \n",
      "         ISSN: 2277 -3754   \n",
      "    ISO 9001:2008 Certified  \n",
      "International Journal of Engineering and Innovative Technology (IJEIT)  \n",
      "Volume 2, Issue 1, July 2012  \n",
      " 189 \n",
      "Introduction to Artificial Neural Network  \n",
      "A.D.Dongare, R.R.Kharde, Amit D.Kachare   \n",
      "Abstract : - This paper presents an emergence of an Artificial \n",
      "Neural Network (ANN) as a tool for analysis of different \n",
      "parameters of a system. An Artificial Neural Network (ANN) is \n",
      "an information -processing paradigm that is inspired by the way \n",
      "biological nervous systems such as brain, process information. \n",
      "ANN consists of multiple layers of simple processing elements \n",
      "called as neurons. The neuron performs two functions, namel y, \n",
      "collection of inputs & generation of an output. Use of ANN \n",
      "provides overview of the theory, learning rules, and applications \n",
      "of the most important neural network models, definitions and \n",
      "style of Computation . The mathematical model of network \n",
      "throws the light on the concept of inputs, weights, summing \n",
      "function, activation function & outputs. Then ANN helps to \n",
      "decide the type of learning for  adjustment of weights with \n",
      "change in parameters. Finally the analysis of a system is \n",
      "completed by ANN implementation  & ANN training & prediction \n",
      "quality.  \n",
      " \n",
      "Keywords:  Biological Inspiration,  ANN Methodology, ANN \n",
      "Implementation and Prediction.  \n",
      " \n",
      "I. INTRODUCTION  \n",
      "Many tasks involving intelligence or pattern recognition \n",
      "are extremely difficult to automate, but appear to be  \n",
      "perfor med very easily by humans. For instance, human s \n",
      "recognize various objects and make sense out of the large \n",
      "amount of visual information in their surroundings, \n",
      "apparently requiring very little effort. It stands to reason \n",
      "that computing systems that attempt s imilar tasks will profit \n",
      "enormou sly from understanding how human s perform these \n",
      "tasks, and simulating these processes to the extent allowed \n",
      "by physical limitations. This necessitates the study and \n",
      "simulation of Neural Networks.  The neural network of an \n",
      "human is part of its nervous system, containing a large \n",
      "number of interconnected neurons (nerve cells). “Neural” is \n",
      "an adjective for neuron, and “Network” denotes a graph like \n",
      "structure. Artificial Neural Network refers to computing \n",
      "systems whose central them e is borrowed from the analogy \n",
      "of biological neural networks.  Artificial Neural Networks \n",
      "are also referred to as “Neural Nets”, artificial neural \n",
      "systems “parallel distributed processing systems” and \n",
      "“connectionist systems”. For a computing system to be \n",
      "called by these pretty names, it is necessary for the system \n",
      "to have a labeled directed graph structure where nodes \n",
      "perform some simple computations. From elementary graph \n",
      "theory we recall that a “Directed Graph” consists of a set of  \n",
      "“Nodes”  (vertices) and  a set of “Connections” \n",
      "(edges/links/arcs) connecting pairs of nodes. In a neural \n",
      "network, each node performs some simple computations, \n",
      "and each connection conveys a signal from one node to \n",
      "another, labeled by a number called the “Connection \n",
      "Strength” or “ Weight” indicating the extent to which a \n",
      "signal is amplified or diminished by connection. This \n",
      "system is the alternative for human expertise and knowledge. Artificial Neural Networks are modeled closely \n",
      "following the brain and therefore a great deal of \n",
      "terminology is borrowed from neuroscience.  \n",
      " \n",
      "II. LITERATURE REVIEW  \n",
      "A.O. Kurban investigated an artificial neural network are \n",
      "non-linear mapping systems with a structure loosely based \n",
      "on principles observed in the biological nervous systems. In \n",
      "greatly simplified t erms from, a typical real neuron has a \n",
      "branching dentritic tree that collects signals from many \n",
      "other neurons in a limited area; a cell body that integrates \n",
      "collected signals and generates a response signal (as well as \n",
      "manages metabolic functions); and alo ng branching axon \n",
      "that distributes the response through contacts with dentritic \n",
      "trees of many other neurons. The response of each neuron is \n",
      "a relatively simple non -linear function of its inputs and is \n",
      "largely determined by the strengths of the connections from \n",
      "its inputs. In spite of the relative simplicity of the individual \n",
      "units, systems containing many neurons can generate \n",
      "complex and intersecting behaviors. In general terms, a NN \n",
      "consists of large number of simple processors linked by \n",
      "weighted connectio ns. By analogy, the processing nodes \n",
      "may be called “neurons”. Each node output depends only on \n",
      "the information that is locally available at the node, either \n",
      "stored internally or arriving via the weighted connections. \n",
      "Each unit receives inputs from many oth er nodes and \n",
      "transmits its output to other nodes. By itself, a single \n",
      "processing element is not very powerful; it generates a \n",
      "scalar output with a single numerical value, which is a \n",
      "simple non -linear function of its inputs. The power of the \n",
      "system emerges from the combination of many units in an \n",
      "appropriate way. A network is utilized different function by \n",
      "varying the connection topology and the values of the \n",
      "connecting weights. Complex functions can be implemented \n",
      "by connecting the units together with appro priate weights. It \n",
      "has been shown that a sufficiently large network with an \n",
      "appropriate structure and property chosen weights can \n",
      "approximate with arbitrary accuracy any function satisfy ing \n",
      "certain broad constraints. [1 ] This model is a drastically \n",
      "simplif ied approximation of real nervous systems. The \n",
      "intent is to capture the major characteristics important in the \n",
      "information processing functions of real networks without \n",
      "varying too much about the physical constraints imposed by \n",
      "biology. Artificial NN are m ade up of simple, highly \n",
      "interconnected processing units called neurons, each of \n",
      "which performs two functions, namely, aggregation of its \n",
      "inputs from other neurons or the external environment and \n",
      "generation of an output from the aggregated inputs. \n",
      "Through this simple structure, neural networks have been \n",
      "shown to be able to approximate most continuous functions \n",
      "to any degree of accuracy, by choice of an appropriate  \n",
      " \n",
      "      \n",
      "         ISSN: 2277 -3754   \n",
      "    ISO 9001:2008 Certified  \n",
      "International Journal of Engineering and Innovative Technology (IJEIT)  \n",
      "Volume 2, Issue 1, July 2012  \n",
      " 190 \n",
      "number of neuron units (Kurban and Yildirim, 2003; \n",
      "Yildirim and Uzmay, 2003) . [2] \n",
      " \n",
      "III. BIOLOG ICAL INSPIRATION  \n",
      "Human brain is made up of a network of neurons that are \n",
      "coupled with receptors and effectors. Receptors are called \n",
      "“dendrites” and effectors are called “axons” .[3] Fig. 1 \n",
      "shows that the dendrites collects the signals from many \n",
      "other neuron s in a limited area; a cell body  or soma that \n",
      "integrates collected signals & generates a response signal & \n",
      "along branching axon that distributes the response through \n",
      "contacts with dendrite trees  of many other neurons. [4]  \n",
      " \n",
      "Fig. 1 Biological Neuron  \n",
      "IV. A NN METHODOLOGY  \n",
      "ANNs  are basically massive parallel computational \n",
      "models that imitate the function of human brain. An ANN \n",
      "consists of large number of simple processors linked by \n",
      "weighted connections. By analogy, the processing nodes \n",
      "may be called “neurons”.  Each node output depends only on \n",
      "the information that is locally available at the node, either \n",
      "stored internally or arriving via the weighted connections. \n",
      "Each unit receives inputs from many other nodes transmits \n",
      "its output to yet another nodes. By itself , a single processing \n",
      "element is not very powerful; it generates a scalar output \n",
      "with single numerical value, which is a simple non -linear \n",
      "function of its inputs. The power of the system emerges from the combination of many units in an appropriate way. \n",
      "[1] The ANN does not really solve the problem in a strictly \n",
      "mathematical sense, but it demonstrates information \n",
      "processing characteristics that give an approximate solution \n",
      "to a given problem. The ANNs have been widely used in \n",
      "complex non linear function mapp ing, image processing, \n",
      "pattern recogni tion & classification & so on. Feed -forward \n",
      "networks are common type of neural networks. A feed \n",
      "forward network comprises an input layer, where the inputs \n",
      "of the problem are received, hidden layers, where the \n",
      "relations hip between the inputs & outputs are determined & \n",
      "represented by synaptic weights, & an output layer which \n",
      "emits the outputs of the problem. The neural feed forward \n",
      "network is modeled with three basic elements:  a) A set of \n",
      "synapses characterized by synapti c weights,  b) An adder or \n",
      "linear combiner for summing the input signals.  c) An \n",
      "activation function for limiting the amplitude of the output \n",
      "of neuron to some finite value. The input of the activation \n",
      "function can be increased by using a bias term. Here, we  \n",
      "have made use of a certain ANN architecture known as the \n",
      "multi -layer -feed-forward neural network or Multi Layer \n",
      "Perceptron (MLP) [5] . \n",
      " \n",
      "Fig.2 Style of Neural Computation\n",
      "In above Fig.2 a n input is presented to the neural network \n",
      "and a corresponding desire d or target response set at the \n",
      "output (when this is the case the training is called \n",
      "supervised). An error is composed from the difference \n",
      "between the desired response and the system output. This \n",
      "error information is fed back to the system and adjusts the \n",
      "system parameters in a systematic fashion (the learning \n",
      "rule). The process is repeated until the performance is \n",
      "acceptable. It is clear from this description that the \n",
      "performance hinges heavily on the data. If one does not \n",
      "have data that cover a significan t portion of the operating \n",
      "conditions or if they are noisy, then neural network \n",
      "technology is probably not the right solution. On the other \n",
      "hand, if there is plenty of data and the problem is poorly \n",
      "understood to derive an approximate model, then neural \n",
      "network technology is a good choice. This operating \n",
      "procedure should be contrasted with the traditional \n",
      "engineering design, made of exhaustive subsystem \n",
      "specifications and intercommunication protocols. In artificial neural networks, the desig ner chooses the network \n",
      "topology, the performance function, the learning rule, and \n",
      "the criterion to stop the training phase, but the system \n",
      "automatically adjusts the parameters. So, it is difficult to \n",
      "bring a priori information into the design, and when the \n",
      "system does no t work properly it is also hard to \n",
      "incrementally refine the solution. But ANN -based solutions \n",
      "are extremely efficient in terms of development time and \n",
      "resources, and in many difficult problems artificial neural \n",
      "networks provide performance that is difficul t to match with \n",
      "other technologies. Denker 10 years ago said that \"artificial \n",
      "neural networks are the second best way to implement a \n",
      "solution\" motivated by the simplicity of their design and \n",
      "because of their universality, only shadowed by the \n",
      "traditional d esign obtained by studying the physics of the \n",
      "problem. At present, artificial neural networks are emerging \n",
      "as the technology of choice for many applications, such as \n",
      "pattern recognition, prediction, system identification, and \n",
      "control.[ 6]  \n",
      " \n",
      "      \n",
      "         ISSN: 2277 -3754   \n",
      "    ISO 9001:2008 Certified  \n",
      "International Journal of Engineering and Innovative Technology (IJEIT)  \n",
      "Volume 2, Issue 1, July 2012  \n",
      " 191 \n",
      "Table 1. Terminolo gy of Neuron  \n",
      "Biological Terminology  ANN Terminology  \n",
      " \n",
      "Neuron  Node/Unit/Cell/Neurode  \n",
      " \n",
      "Synapse  Connection/Edge/Link  \n",
      " \n",
      "Synaptic Efficiency  Connection Strength/Weight  \n",
      " \n",
      "Firing Frequency  Node Output  \n",
      " \n",
      "A. Mathematical Model  \n",
      "When creating a functional model of t he biological \n",
      "neuron, there are three basic components of importance. \n",
      "First, the synapses of the neuron are modeled as weights. \n",
      "The strength of the connection between an input and a \n",
      "neuron is noted by the value of the weight. Negative weight \n",
      "values reflect  inhibitory connections, while positive values \n",
      "designate excitatory connections [Haykin]. The next two \n",
      "components model the actual activity within the neuron cell. \n",
      "An adder sums up all the inputs modified by their respective \n",
      "weights. This activity is refer red to as linear combination. \n",
      "Finally, an activation function controls the amplitude of the \n",
      "output of the neuron. An acceptable range of output is \n",
      "usually between 0 and 1, or -1 and 1.  Mathematically, this \n",
      "process is described in the figure,  \n",
      " \n",
      "Fig. 3 Math ematical Model  \n",
      "From this model the interval activity of the neuron can be \n",
      "shown to be,  \n",
      "                                          (1) \n",
      "The output of the neuron, Yk, would therefore be the \n",
      "outcome of some activation function on the value of Vk. [ 7] \n",
      "B. Feed F orward Networks  \n",
      "This is a subclass of acrylic networks in which a \n",
      "connection is allowed from a node in layer i only to nodes \n",
      "in layer i+1 as shown in Fig.4 . These networks are \n",
      "succinctly described by a sequence of numbers indicating \n",
      "the number of nodes in each layer. For instance, the network shown in Fig. 4 is a 3 -2-3-2 feed forward network; \n",
      "it contains three nodes in the input layer (layer 0), two \n",
      "nodes in the first hidden layer (layer 1), three nodes in the \n",
      "second hidden layer (layer 2), and two nodes in  the output \n",
      "layer (layer 3).  These networks, generally with no more \n",
      "than four such layers, are among the most common neural \n",
      "nets in use, so much so that some users identify the phrase \n",
      "“neural networks” to mean only feed forward networks. \n",
      "Conceptually, node s in successively higher layers abstract \n",
      "successively higher level features from preceding layers. In \n",
      "the literature on neural networks, the term “feed forward” \n",
      "has been used sometimes to refer to layered or acrylic \n",
      "networks. [ 8]        \n",
      " \n",
      "Fig. 4 Feed Forwa rd Networks  \n",
      "C. Neural Learning  \n",
      "It is reasonable to conjecture that neurons in an animal’s \n",
      "brain are “hard wired.” It is equally obvious that animals, \n",
      "especially the higher order animals, learn as they grow. \n",
      "How does this learning occur? What are possible \n",
      "mathematical models of learning?  In this section, we \n",
      "summarize some of the basic theories of biological learning \n",
      "and their adaptations for artificial neural networks. In \n",
      "artificial neural networks, learning refers to the method of \n",
      "modifying the weights of c onnections between the nodes of \n",
      "a specified network.  Learning is the process by which the \n",
      "random -valued parameters (Weights and bias) of a neural \n",
      "network are adapted through a continuous process of \n",
      "simulation by the environment in which network is \n",
      "embedded . Learning rate is defined as the rate at which \n",
      "network gets adapted. Type of learning is determined by the \n",
      "manner in which parameter change takes place. Learning \n",
      "may be categorized as supervised learning, unsupervised  \n",
      "learning and r einforced learning.  In Supervised learning,  a \n",
      "teacher is available to indicate whether a system is \n",
      "performing correctly, or to indicate a desired response, or to \n",
      "validate the acceptability of a system’s responses, or to \n",
      "indicate the amount of error in system performance. This is  \n",
      "in contrast with unsupervised learning, where no teacher is \n",
      "available and learning must rely on guidance obtained \n",
      "heuristically by the system examining different sample data \n",
      "or the environment. Learning is similar to training i.e. one \n",
      "has to learn somethi ng which is analogous to one has to be \n",
      "trained. A neural network has to be configured such that the \n",
      "application of a set of inputs produces (either 'direct' or via \n",
      "a relaxation process) the desired set of outputs. Various \n",
      "methods to set the strengths of th e connections exist. One \n",
      "way is to set the weights explicitly, using a priori  \n",
      " \n",
      "      \n",
      "         ISSN: 2277 -3754   \n",
      "    ISO 9001:2008 Certified  \n",
      "International Journal of Engineering and Innovative Technology (IJEIT)  \n",
      "Volume 2, Issue 1, July 2012  \n",
      " 192 \n",
      "knowledge. Another way is to 'train' the neural network by \n",
      "feeding it teaching patterns and letting it change its weights \n",
      "according to some learning rule. We  can categorize the \n",
      "learning situations in two distinct sorts. These are  \n",
      "1. Supervised Learning  \n",
      "Supervised learning  or Associative learning in which the \n",
      "network is trained by providing it with input and matching \n",
      "output patterns. These input -output pairs can be provided by \n",
      "an external teacher, or by the system which contains the \n",
      "neural network (self -supervised).  Example:  An \n",
      "archaeologist discovers a human skeleton and has to \n",
      "determine whether it belonged to man or woman. In doing \n",
      "this, the archaeologist is guided by many past ex amples of \n",
      "male and female skeletons. Examination of these past \n",
      "examples (called the training set) allows the archaeologist \n",
      "to learn about the distinctions between male and female \n",
      "skeletons. This learning process is an example of supervised \n",
      "learning, and th e result of learning process can be applied to \n",
      "determine whether the newly discovered skeleton belongs to \n",
      "man or woman.  \n",
      " \n",
      "Fig. 5 Supervised Learning  \n",
      "2 .Unsupervised Learning  \n",
      "Unsupervised learning  or Self -organization in which an \n",
      "(output) unit is trained to  respond to clusters of pattern \n",
      "within the input. In this paradigm the system is supposed to \n",
      "discover statistically salient features of the input population. \n",
      "Unlike the supervised learning paradigm, there is no a priori \n",
      "set of categories into which the pat terns are to be classified; \n",
      "rather the system must develop its own representation of the \n",
      "input stimuli. Example:  In a different situation, the \n",
      "archaeologist has to determine whether a set of skeleton \n",
      "fragments belong to the same dinosaur species or need to  be \n",
      "differentiated into different species. For this task, no \n",
      "previous data may be available to clearly identify the \n",
      "species for each skeleton fragment. The archaeologist has to \n",
      "determine whether the skeletons (that can be reconstructed \n",
      "from the fragments) are sufficiently similar to belong to the \n",
      "same species, or if the differences between these skeletons \n",
      "are large enough to warrant grouping them into different \n",
      "species. This is an unsupervised learning process, which \n",
      "involves estimating the magnitudes of di fferences between \n",
      "the skeletons. One archaeologist may believe the skeletons \n",
      "belong to different species, while another may disagree, and \n",
      "there is no absolute criterion to determine who is correct.    \n",
      " 3 .Reinforced Learning  \n",
      "Reinforcement Learning  is type of learning may be \n",
      "considered as an intermediate form of the above two types \n",
      "of learning. Here the learning machine does some action on \n",
      "the environment and gets a feedback response from the \n",
      "environment.  The learning system grades its action good \n",
      "(rewarding ) or bad (punishable) based on the environmental \n",
      "response and accordingly adjusts its parameters. Generally, \n",
      "parameter adjustment is continued until an equilibrium state \n",
      "occurs, following which there will be       no more changes \n",
      "in its parameters. The sel f organizing neural learning may \n",
      "be categorized under this type of learning. [ 7] \n",
      "D. Back Propagation Network  \n",
      "The back propagation algorithm (Rumelhart and \n",
      "McClelland, 1986) is used in  layered feed -forward ANNs. \n",
      "This means that the artificial neurons are  organized in \n",
      "layers,  and send their signals “forward”, and then the errors \n",
      "are propagated backwards. The network receives inputs by \n",
      "neurons in the input layer , and the output of the network is \n",
      "given  by the neurons on an output layer . There may be one \n",
      "or m ore intermediate hidden layers . The back propagation \n",
      "algorithm uses supervised learning, which means that we \n",
      "provide the  algorithm with examples of the inputs and \n",
      "outputs we want the network to compute, and  then the error \n",
      "(difference between actual and exp ected results) is \n",
      "calculated. The idea of  the back propagation algorithm is to \n",
      "reduce this error, until the ANN learns the training  data. \n",
      "The training begins with random weights, and the goal is to \n",
      "adjust them so that the  error will be minimal.  [9] Back \n",
      "propagation network has gained importance due to the \n",
      "shortcomings of other available networks. The network is a \n",
      "multi layer network (multi layer perception) that contains at \n",
      "least one hidden layer in addition to input and output layers. \n",
      "Number of hidden laye rs & numbers of neurons in each \n",
      "hidden layer is to be fixed based on application, the \n",
      "complexity of the problem and the number of inputs and \n",
      "outputs. Use of non -linear log -sigmoid transfer function \n",
      "enables the network to simulate non -linearity in practical  \n",
      "systems. Due to this numerous advantages, back \n",
      "propagation network is chosen for present work.  [3] \n",
      "Implementation of back propagation model consists of two \n",
      "phases. First phase is known as training while the second \n",
      "phase is called Testing. Training, in bac k propagation is \n",
      "based on gradient decent rule that tends to adjust weights \n",
      "and reduce system error in the network. Input layer has \n",
      "neurons equal in number to that of the inputs. Similarly, \n",
      "output layer neurons are same in the number as number of \n",
      "outputs. Number of hidden layer neurons is deciding by trial \n",
      "and error method using the experimental data. [ 10] \n",
      "E.ANN Development & Implementation  \n",
      "In this work, both ANN implementation & training is \n",
      "developed, using the neural network toolbox of Mat Lab. \n",
      "Different ANNs are build rather than using one large ANN \n",
      "including all the output variables. This strategy allowed for \n",
      "better adjustment of the ANN for each specific problem, \n",
      "including the optimization of the architecture for each \n",
      "output.   .   \n",
      " \n",
      "      \n",
      "         ISSN: 2277 -3754   \n",
      "    ISO 9001:2008 Certified  \n",
      "International Journal of Engineering and Innovative Technology (IJEIT)  \n",
      "Volume 2, Issue 1, July 2012  \n",
      " 193 \n",
      "F. ANN Training & Predicti on quality  \n",
      "One of the most relevant aspects of a neural network is \n",
      "its ability to generalize, that is, to predict cases that are not \n",
      "included in the training set. One of the problems that occur \n",
      "during neural network training is called over fitting. The \n",
      "error on the training set is driven to a very small value, but \n",
      "when new data is presented to the network, the error is \n",
      "large. The network has memorized the training examples, \n",
      "but it has not learned to generalize to new situations. One \n",
      "method for improving net work generalization is to use a \n",
      "network that is just large enough to provide an adequate fit. \n",
      "The larger network you use the more complex functions the \n",
      "network can create. There are two other methods for \n",
      "improving generalization that are implemented in Mat  Lab \n",
      "Neural Network Toolbox software: regularization & early \n",
      "stopping.  The typical performance function used for \n",
      "training feed forward neural networks is the mean sum o f \n",
      "squares of the network errors,  \n",
      "             (2) \n",
      "It is possible to improve generalizat ion, if you modify the \n",
      "performance function by adding a term that consists of the \n",
      "mean of the sum of the squares of the network weights & \n",
      "biases,  \n",
      "msereg = λmse +(1 -λ)msw,                                       (3)    \n",
      "Where λ  is the performance ratio, &  \n",
      "                                              (4)  \n",
      "Using this performance function causes the network to have \n",
      "smaller weights & biases, & this force t he network response \n",
      "to be smoother & less likely to over fit.  Once the different \n",
      "stages of the training process & the ANN structure had been \n",
      "determined, & before the optimization procedure is \n",
      "developed, it is important to estimate the ANN prediction \n",
      "qualit ies. There is excellent agreement of predicted values \n",
      "& expected values. This close agreement shows that the \n",
      "ANN can be used in the data analysis, of theoretical work to \n",
      "generate the missing data in the theoretical program. The \n",
      "results of model ANN are com pared with the hydrodynamic \n",
      "simulation data. [ 6] \n",
      "V. ANN FOR HYDRODYNAMIC JOURNAL \n",
      "BEARING  \n",
      "The Artificial Neural Network can be used for prediction \n",
      "of pressure distribution in hydrodynamic journal bearing \n",
      "which can be further used for stability analysis of \n",
      "hydrodynamic journal bearing.  [11]. \n",
      " \n",
      "VI. CONCLUSION  \n",
      "As the ANN is an emerging technology it can be used for \n",
      "data analysis in applications such as pattern recognition, \n",
      "prediction, system identification & control. From above \n",
      "theories it can be seen that ANN i s a radial basis function back propagation network. The network is capable of \n",
      "predicting the parameters by experimental system. The \n",
      "network has parallel structure and fast learning capacity. \n",
      "The collected experimental data such as speed, load, & \n",
      "values of pressure distribution  etc. are also employed as \n",
      "training and testing data for an artificial neural network. \n",
      "The neural network is a feed forward three layered network. \n",
      "Quick propagation algorithm is used to update the weight of \n",
      "the network during the train ing. The ANN has a superior \n",
      "performance to follow the desired results of the system and \n",
      "is employed to analyze such systems parameters in practical \n",
      "applications.    \n",
      "VII. ACKNOWLEDGEMENT  \n",
      "The authors would like to acknowledge & thanks to Dr. \n",
      "Y.R. Kharde , Principal, and Shree . Saibaba Institute of \n",
      "Engineering Research  & Allied Sciences , Rahata, Prof. S.B. \n",
      "Belkar, Asso. Prof., P.R.E.C. Loni & Prof. R.R. Navthar, \n",
      "Asstt. Prof., P.D.V.V.P. COE Ahmednagar for their \n",
      "immense help in this work.  \n",
      " \n",
      "REFERENCES  \n",
      "[1] A.O. Kurban , “Analysis of shafts surface pressures   using \n",
      "neural network”,  Industrial Lubrication and Tribology, \n",
      "(2004), Volume 56, No. 4, Page no. 217 -225. \n",
      "[2] Fazil Canbulut, Cem Sinanoglu and Sahin Yildirim, “Neural \n",
      "network analysis of leakage oil quantity in the des ign of \n",
      "partially hydrostatic slipper bearings”,  Industrial Lubrication \n",
      "and Tribology, (2004), Volume 56, No. 4, Page no. 231 -243 \n",
      "[3] Dr. R. R. Srikanth. “Application of ANN in Condition \n",
      "Monitoring: A Case Study”, (Conference proceeding \n",
      "“Condition Monitoring of  Mechanical System”) (2009), \n",
      "Gitam University, Vishakhapattanam, Page no. 31 -44. \n",
      "[4] R.R.Navthar & Dr. N.V. Halegowda, “Analysis of oil film \n",
      "thickness in Hydrodynamic Journal Bearing using Artificial \n",
      "Neural Networks”, Ciit International Journal of Artificial \n",
      "Intelligent System & Machine Learning (Nov. 2011), Volume \n",
      "3, No.12, Page no. -762-766 \n",
      "[5] M. Ananda Rao & J. Srinivas, “Dynamics of rotors supported \n",
      "on fluid film bearings using neural networks”,  Centre for \n",
      "System Dynamics & Condition Monitoring & Diagnostic \n",
      "Studies, Page no.149 -155 \n",
      "[6] Ghorbanian, M. Ahmadi, R. Soltani, “Design predictive tool \n",
      "& optimization of journal bearing using neural network \n",
      "model & multi objective genetic algorithm”, Scientia Iranica \n",
      "B (2011), Volume 18, No.5 Page no. -1095 -1105  \n",
      "[7] “Neural netwo rks: A requirement for intelligent systems”  \n",
      "[8] Kishan Mehrotra, Chilkuri K. Mohan, Sanjay Ranka, \n",
      "“Elements of Artificial Neural Networks”, Penram \n",
      "International Publishing (India), (1997), Volume 1, Page no. -\n",
      "1-41.  \n",
      "[9] Carlos Gershenson, ”Artificial Neural Network  for \n",
      "Beginners”  \n",
      "[10] R.R.Navthar & Dr. N.V. Halegowda, “Applications of \n",
      "Artificial Neural Network in Pressure Distribution Analysis \n",
      "of Hydrodynamic Journal Bearings”,  ASME Digital Library, \n",
      "e-books , International Conference on Computer Technology  \n",
      " \n",
      "      \n",
      "         ISSN: 2277 -3754   \n",
      "    ISO 9001:2008 Certified  \n",
      "International Journal of Engineering and Innovative Technology (IJEIT)  \n",
      "Volume 2, Issue 1, July 2012  \n",
      " 194 \n",
      "& Development ( 2011),  (Third ICCTD 2011) , Page no. -\n",
      "717-722 \n",
      "[11] R.R.Navthar & Dr. N.V. Halegowda, “Pressure  Distribution \n",
      "Analysis of Hydrodynamic Journal Bearings using Artificial \n",
      "Neural Network”,  ASME Digital Library, e-books , \n",
      "International Conference on Computer & Autom ation \n",
      "Engineering, (Fourth ICCAE 2012), Page no. -153-161 \n",
      " \n",
      "AUTHOR BIOGRAPHY  \n",
      " \n",
      "Prof.A.D. Dongare  \n",
      "M.E. (Design Engg), Ph.D.(App)  \n",
      "P.R.E.C. Loni Rahata Ahmednagar.  \n",
      "Area of Research:  Design and Tribology.  \n",
      "Professional Membership: IE (I).  \n",
      " \n",
      " Prof.R.R. Kharde  \n",
      "M.E. (Tribology), Head, Dept. of \n",
      "Mechanical Engineering.  \n",
      "P.R.E.C. Loni Rahata Ahmednagar.  \n",
      "Area of Research:  Design and Tribology.  \n",
      "Professional Membership: IE (I).  \n",
      " \n",
      " \n",
      "A.D. Kachare  \n",
      "B.E. (Mechanical), P.G. Student.  \n",
      "P.R.E.C. Loni Rahata Ahmednagar.  \n",
      "Area of Research:  Design.  \n",
      "Professional Membership:  IE (I).  \n",
      " \n",
      "  \n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Extract text in the pdf file \n",
    "text  = ''\n",
    "for i in pdf_reader.pages:\n",
    "    text += i.extract_text()\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg')\n",
    "nlp.max_length = 1198623"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data / Text Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences: 562\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[' ',\n",
       " ' ',\n",
       " '      ',\n",
       " '         ISSN: 2277 -3754   ',\n",
       " '    ISO 9001:2008 Certified  ',\n",
       " 'International Journal of Engineering and Innovative Technology (IJEIT)  ',\n",
       " 'Volume 2, Issue 1, July 2012  ',\n",
       " ' 189 ',\n",
       " 'Introduction to Artificial Neural Network  ',\n",
       " 'A.D.Dongare, R.R.Kharde, Amit D.Kachare   ',\n",
       " 'Abstract : - This paper presents an emergence of an Artificial ',\n",
       " 'Neural Network (ANN) as a tool for analysis of different ',\n",
       " 'parameters of a system. An Artificial Neural Network (ANN) is ',\n",
       " 'an information -processing paradigm that is inspired by the way ',\n",
       " 'biological nervous systems such as brain, process information. ',\n",
       " 'ANN consists of multiple layers of simple processing elements ',\n",
       " 'called as neurons. The neuron performs two functions, namel y, ',\n",
       " 'collection of inputs & generation of an output. Use of ANN ',\n",
       " 'provides overview of the theory, learning rules, and applications ',\n",
       " 'of the most important neural network models, definitions and ',\n",
       " 'style of Computation . The mathematical model of network ',\n",
       " 'throws the light on the concept of inputs, weights, summing ',\n",
       " 'function, activation function & outputs. Then ANN helps to ',\n",
       " 'decide the type of learning for  adjustment of weights with ',\n",
       " 'change in parameters. Finally the analysis of a system is ',\n",
       " 'completed by ANN implementation  & ANN training & prediction ',\n",
       " 'quality.  ',\n",
       " ' ',\n",
       " 'Keywords:  Biological Inspiration,  ANN Methodology, ANN ',\n",
       " 'Implementation and Prediction.  ',\n",
       " ' ',\n",
       " 'I. INTRODUCTION  ',\n",
       " 'Many tasks involving intelligence or pattern recognition ',\n",
       " 'are extremely difficult to automate, but appear to be  ',\n",
       " 'perfor med very easily by humans. For instance, human s ',\n",
       " 'recognize various objects and make sense out of the large ',\n",
       " 'amount of visual information in their surroundings, ',\n",
       " 'apparently requiring very little effort. It stands to reason ',\n",
       " 'that computing systems that attempt s imilar tasks will profit ',\n",
       " 'enormou sly from understanding how human s perform these ',\n",
       " 'tasks, and simulating these processes to the extent allowed ',\n",
       " 'by physical limitations. This necessitates the study and ',\n",
       " 'simulation of Neural Networks.  The neural network of an ',\n",
       " 'human is part of its nervous system, containing a large ',\n",
       " 'number of interconnected neurons (nerve cells). “Neural” is ',\n",
       " 'an adjective for neuron, and “Network” denotes a graph like ',\n",
       " 'structure. Artificial Neural Network refers to computing ',\n",
       " 'systems whose central them e is borrowed from the analogy ',\n",
       " 'of biological neural networks.  Artificial Neural Networks ',\n",
       " 'are also referred to as “Neural Nets”, artificial neural ',\n",
       " 'systems “parallel distributed processing systems” and ',\n",
       " '“connectionist systems”. For a computing system to be ',\n",
       " 'called by these pretty names, it is necessary for the system ',\n",
       " 'to have a labeled directed graph structure where nodes ',\n",
       " 'perform some simple computations. From elementary graph ',\n",
       " 'theory we recall that a “Directed Graph” consists of a set of  ',\n",
       " '“Nodes”  (vertices) and  a set of “Connections” ',\n",
       " '(edges/links/arcs) connecting pairs of nodes. In a neural ',\n",
       " 'network, each node performs some simple computations, ',\n",
       " 'and each connection conveys a signal from one node to ',\n",
       " 'another, labeled by a number called the “Connection ',\n",
       " 'Strength” or “ Weight” indicating the extent to which a ',\n",
       " 'signal is amplified or diminished by connection. This ',\n",
       " 'system is the alternative for human expertise and knowledge. Artificial Neural Networks are modeled closely ',\n",
       " 'following the brain and therefore a great deal of ',\n",
       " 'terminology is borrowed from neuroscience.  ',\n",
       " ' ',\n",
       " 'II. LITERATURE REVIEW  ',\n",
       " 'A.O. Kurban investigated an artificial neural network are ',\n",
       " 'non-linear mapping systems with a structure loosely based ',\n",
       " 'on principles observed in the biological nervous systems. In ',\n",
       " 'greatly simplified t erms from, a typical real neuron has a ',\n",
       " 'branching dentritic tree that collects signals from many ',\n",
       " 'other neurons in a limited area; a cell body that integrates ',\n",
       " 'collected signals and generates a response signal (as well as ',\n",
       " 'manages metabolic functions); and alo ng branching axon ',\n",
       " 'that distributes the response through contacts with dentritic ',\n",
       " 'trees of many other neurons. The response of each neuron is ',\n",
       " 'a relatively simple non -linear function of its inputs and is ',\n",
       " 'largely determined by the strengths of the connections from ',\n",
       " 'its inputs. In spite of the relative simplicity of the individual ',\n",
       " 'units, systems containing many neurons can generate ',\n",
       " 'complex and intersecting behaviors. In general terms, a NN ',\n",
       " 'consists of large number of simple processors linked by ',\n",
       " 'weighted connectio ns. By analogy, the processing nodes ',\n",
       " 'may be called “neurons”. Each node output depends only on ',\n",
       " 'the information that is locally available at the node, either ',\n",
       " 'stored internally or arriving via the weighted connections. ',\n",
       " 'Each unit receives inputs from many oth er nodes and ',\n",
       " 'transmits its output to other nodes. By itself, a single ',\n",
       " 'processing element is not very powerful; it generates a ',\n",
       " 'scalar output with a single numerical value, which is a ',\n",
       " 'simple non -linear function of its inputs. The power of the ',\n",
       " 'system emerges from the combination of many units in an ',\n",
       " 'appropriate way. A network is utilized different function by ',\n",
       " 'varying the connection topology and the values of the ',\n",
       " 'connecting weights. Complex functions can be implemented ',\n",
       " 'by connecting the units together with appro priate weights. It ',\n",
       " 'has been shown that a sufficiently large network with an ',\n",
       " 'appropriate structure and property chosen weights can ',\n",
       " 'approximate with arbitrary accuracy any function satisfy ing ',\n",
       " 'certain broad constraints. [1 ] This model is a drastically ',\n",
       " 'simplif ied approximation of real nervous systems. The ',\n",
       " 'intent is to capture the major characteristics important in the ',\n",
       " 'information processing functions of real networks without ',\n",
       " 'varying too much about the physical constraints imposed by ',\n",
       " 'biology. Artificial NN are m ade up of simple, highly ',\n",
       " 'interconnected processing units called neurons, each of ',\n",
       " 'which performs two functions, namely, aggregation of its ',\n",
       " 'inputs from other neurons or the external environment and ',\n",
       " 'generation of an output from the aggregated inputs. ',\n",
       " 'Through this simple structure, neural networks have been ',\n",
       " 'shown to be able to approximate most continuous functions ',\n",
       " 'to any degree of accuracy, by choice of an appropriate  ',\n",
       " ' ',\n",
       " '      ',\n",
       " '         ISSN: 2277 -3754   ',\n",
       " '    ISO 9001:2008 Certified  ',\n",
       " 'International Journal of Engineering and Innovative Technology (IJEIT)  ',\n",
       " 'Volume 2, Issue 1, July 2012  ',\n",
       " ' 190 ',\n",
       " 'number of neuron units (Kurban and Yildirim, 2003; ',\n",
       " 'Yildirim and Uzmay, 2003) . [2] ',\n",
       " ' ',\n",
       " 'III. BIOLOG ICAL INSPIRATION  ',\n",
       " 'Human brain is made up of a network of neurons that are ',\n",
       " 'coupled with receptors and effectors. Receptors are called ',\n",
       " '“dendrites” and effectors are called “axons” .[3] Fig. 1 ',\n",
       " 'shows that the dendrites collects the signals from many ',\n",
       " 'other neuron s in a limited area; a cell body  or soma that ',\n",
       " 'integrates collected signals & generates a response signal & ',\n",
       " 'along branching axon that distributes the response through ',\n",
       " 'contacts with dendrite trees  of many other neurons. [4]  ',\n",
       " ' ',\n",
       " 'Fig. 1 Biological Neuron  ',\n",
       " 'IV. A NN METHODOLOGY  ',\n",
       " 'ANNs  are basically massive parallel computational ',\n",
       " 'models that imitate the function of human brain. An ANN ',\n",
       " 'consists of large number of simple processors linked by ',\n",
       " 'weighted connections. By analogy, the processing nodes ',\n",
       " 'may be called “neurons”.  Each node output depends only on ',\n",
       " 'the information that is locally available at the node, either ',\n",
       " 'stored internally or arriving via the weighted connections. ',\n",
       " 'Each unit receives inputs from many other nodes transmits ',\n",
       " 'its output to yet another nodes. By itself , a single processing ',\n",
       " 'element is not very powerful; it generates a scalar output ',\n",
       " 'with single numerical value, which is a simple non -linear ',\n",
       " 'function of its inputs. The power of the system emerges from the combination of many units in an appropriate way. ',\n",
       " '[1] The ANN does not really solve the problem in a strictly ',\n",
       " 'mathematical sense, but it demonstrates information ',\n",
       " 'processing characteristics that give an approximate solution ',\n",
       " 'to a given problem. The ANNs have been widely used in ',\n",
       " 'complex non linear function mapp ing, image processing, ',\n",
       " 'pattern recogni tion & classification & so on. Feed -forward ',\n",
       " 'networks are common type of neural networks. A feed ',\n",
       " 'forward network comprises an input layer, where the inputs ',\n",
       " 'of the problem are received, hidden layers, where the ',\n",
       " 'relations hip between the inputs & outputs are determined & ',\n",
       " 'represented by synaptic weights, & an output layer which ',\n",
       " 'emits the outputs of the problem. The neural feed forward ',\n",
       " 'network is modeled with three basic elements:  a) A set of ',\n",
       " 'synapses characterized by synapti c weights,  b) An adder or ',\n",
       " 'linear combiner for summing the input signals.  c) An ',\n",
       " 'activation function for limiting the amplitude of the output ',\n",
       " 'of neuron to some finite value. The input of the activation ',\n",
       " 'function can be increased by using a bias term. Here, we  ',\n",
       " 'have made use of a certain ANN architecture known as the ',\n",
       " 'multi -layer -feed-forward neural network or Multi Layer ',\n",
       " 'Perceptron (MLP) [5] . ',\n",
       " ' ',\n",
       " 'Fig.2 Style of Neural Computation',\n",
       " 'In above Fig.2 a n input is presented to the neural network ',\n",
       " 'and a corresponding desire d or target response set at the ',\n",
       " 'output (when this is the case the training is called ',\n",
       " 'supervised). An error is composed from the difference ',\n",
       " 'between the desired response and the system output. This ',\n",
       " 'error information is fed back to the system and adjusts the ',\n",
       " 'system parameters in a systematic fashion (the learning ',\n",
       " 'rule). The process is repeated until the performance is ',\n",
       " 'acceptable. It is clear from this description that the ',\n",
       " 'performance hinges heavily on the data. If one does not ',\n",
       " 'have data that cover a significan t portion of the operating ',\n",
       " 'conditions or if they are noisy, then neural network ',\n",
       " 'technology is probably not the right solution. On the other ',\n",
       " 'hand, if there is plenty of data and the problem is poorly ',\n",
       " 'understood to derive an approximate model, then neural ',\n",
       " 'network technology is a good choice. This operating ',\n",
       " 'procedure should be contrasted with the traditional ',\n",
       " 'engineering design, made of exhaustive subsystem ',\n",
       " 'specifications and intercommunication protocols. In artificial neural networks, the desig ner chooses the network ',\n",
       " 'topology, the performance function, the learning rule, and ',\n",
       " 'the criterion to stop the training phase, but the system ',\n",
       " 'automatically adjusts the parameters. So, it is difficult to ',\n",
       " 'bring a priori information into the design, and when the ',\n",
       " 'system does no t work properly it is also hard to ',\n",
       " 'incrementally refine the solution. But ANN -based solutions ',\n",
       " 'are extremely efficient in terms of development time and ',\n",
       " 'resources, and in many difficult problems artificial neural ',\n",
       " 'networks provide performance that is difficul t to match with ',\n",
       " 'other technologies. Denker 10 years ago said that \"artificial ',\n",
       " 'neural networks are the second best way to implement a ',\n",
       " 'solution\" motivated by the simplicity of their design and ',\n",
       " 'because of their universality, only shadowed by the ',\n",
       " 'traditional d esign obtained by studying the physics of the ',\n",
       " 'problem. At present, artificial neural networks are emerging ',\n",
       " 'as the technology of choice for many applications, such as ',\n",
       " 'pattern recognition, prediction, system identification, and ',\n",
       " 'control.[ 6]  ',\n",
       " ' ',\n",
       " '      ',\n",
       " '         ISSN: 2277 -3754   ',\n",
       " '    ISO 9001:2008 Certified  ',\n",
       " 'International Journal of Engineering and Innovative Technology (IJEIT)  ',\n",
       " 'Volume 2, Issue 1, July 2012  ',\n",
       " ' 191 ',\n",
       " 'Table 1. Terminolo gy of Neuron  ',\n",
       " 'Biological Terminology  ANN Terminology  ',\n",
       " ' ',\n",
       " 'Neuron  Node/Unit/Cell/Neurode  ',\n",
       " ' ',\n",
       " 'Synapse  Connection/Edge/Link  ',\n",
       " ' ',\n",
       " 'Synaptic Efficiency  Connection Strength/Weight  ',\n",
       " ' ',\n",
       " 'Firing Frequency  Node Output  ',\n",
       " ' ',\n",
       " 'A. Mathematical Model  ',\n",
       " 'When creating a functional model of t he biological ',\n",
       " 'neuron, there are three basic components of importance. ',\n",
       " 'First, the synapses of the neuron are modeled as weights. ',\n",
       " 'The strength of the connection between an input and a ',\n",
       " 'neuron is noted by the value of the weight. Negative weight ',\n",
       " 'values reflect  inhibitory connections, while positive values ',\n",
       " 'designate excitatory connections [Haykin]. The next two ',\n",
       " 'components model the actual activity within the neuron cell. ',\n",
       " 'An adder sums up all the inputs modified by their respective ',\n",
       " 'weights. This activity is refer red to as linear combination. ',\n",
       " 'Finally, an activation function controls the amplitude of the ',\n",
       " 'output of the neuron. An acceptable range of output is ',\n",
       " 'usually between 0 and 1, or -1 and 1.  Mathematically, this ',\n",
       " 'process is described in the figure,  ',\n",
       " ' ',\n",
       " 'Fig. 3 Math ematical Model  ',\n",
       " 'From this model the interval activity of the neuron can be ',\n",
       " 'shown to be,  ',\n",
       " '                                          (1) ',\n",
       " 'The output of the neuron, Yk, would therefore be the ',\n",
       " 'outcome of some activation function on the value of Vk. [ 7] ',\n",
       " 'B. Feed F orward Networks  ',\n",
       " 'This is a subclass of acrylic networks in which a ',\n",
       " 'connection is allowed from a node in layer i only to nodes ',\n",
       " 'in layer i+1 as shown in Fig.4 . These networks are ',\n",
       " 'succinctly described by a sequence of numbers indicating ',\n",
       " 'the number of nodes in each layer. For instance, the network shown in Fig. 4 is a 3 -2-3-2 feed forward network; ',\n",
       " 'it contains three nodes in the input layer (layer 0), two ',\n",
       " 'nodes in the first hidden layer (layer 1), three nodes in the ',\n",
       " 'second hidden layer (layer 2), and two nodes in  the output ',\n",
       " 'layer (layer 3).  These networks, generally with no more ',\n",
       " 'than four such layers, are among the most common neural ',\n",
       " 'nets in use, so much so that some users identify the phrase ',\n",
       " '“neural networks” to mean only feed forward networks. ',\n",
       " 'Conceptually, node s in successively higher layers abstract ',\n",
       " 'successively higher level features from preceding layers. In ',\n",
       " 'the literature on neural networks, the term “feed forward” ',\n",
       " 'has been used sometimes to refer to layered or acrylic ',\n",
       " 'networks. [ 8]        ',\n",
       " ' ',\n",
       " 'Fig. 4 Feed Forwa rd Networks  ',\n",
       " 'C. Neural Learning  ',\n",
       " 'It is reasonable to conjecture that neurons in an animal’s ',\n",
       " 'brain are “hard wired.” It is equally obvious that animals, ',\n",
       " 'especially the higher order animals, learn as they grow. ',\n",
       " 'How does this learning occur? What are possible ',\n",
       " 'mathematical models of learning?  In this section, we ',\n",
       " 'summarize some of the basic theories of biological learning ',\n",
       " 'and their adaptations for artificial neural networks. In ',\n",
       " 'artificial neural networks, learning refers to the method of ',\n",
       " 'modifying the weights of c onnections between the nodes of ',\n",
       " 'a specified network.  Learning is the process by which the ',\n",
       " 'random -valued parameters (Weights and bias) of a neural ',\n",
       " 'network are adapted through a continuous process of ',\n",
       " 'simulation by the environment in which network is ',\n",
       " 'embedded . Learning rate is defined as the rate at which ',\n",
       " 'network gets adapted. Type of learning is determined by the ',\n",
       " 'manner in which parameter change takes place. Learning ',\n",
       " 'may be categorized as supervised learning, unsupervised  ',\n",
       " 'learning and r einforced learning.  In Supervised learning,  a ',\n",
       " 'teacher is available to indicate whether a system is ',\n",
       " 'performing correctly, or to indicate a desired response, or to ',\n",
       " 'validate the acceptability of a system’s responses, or to ',\n",
       " 'indicate the amount of error in system performance. This is  ',\n",
       " 'in contrast with unsupervised learning, where no teacher is ',\n",
       " 'available and learning must rely on guidance obtained ',\n",
       " 'heuristically by the system examining different sample data ',\n",
       " 'or the environment. Learning is similar to training i.e. one ',\n",
       " 'has to learn somethi ng which is analogous to one has to be ',\n",
       " 'trained. A neural network has to be configured such that the ',\n",
       " \"application of a set of inputs produces (either 'direct' or via \",\n",
       " 'a relaxation process) the desired set of outputs. Various ',\n",
       " 'methods to set the strengths of th e connections exist. One ',\n",
       " 'way is to set the weights explicitly, using a priori  ',\n",
       " ' ',\n",
       " '      ',\n",
       " '         ISSN: 2277 -3754   ',\n",
       " '    ISO 9001:2008 Certified  ',\n",
       " 'International Journal of Engineering and Innovative Technology (IJEIT)  ',\n",
       " 'Volume 2, Issue 1, July 2012  ',\n",
       " ' 192 ',\n",
       " \"knowledge. Another way is to 'train' the neural network by \",\n",
       " 'feeding it teaching patterns and letting it change its weights ',\n",
       " 'according to some learning rule. We  can categorize the ',\n",
       " 'learning situations in two distinct sorts. These are  ',\n",
       " '1. Supervised Learning  ',\n",
       " 'Supervised learning  or Associative learning in which the ',\n",
       " 'network is trained by providing it with input and matching ',\n",
       " 'output patterns. These input -output pairs can be provided by ',\n",
       " 'an external teacher, or by the system which contains the ',\n",
       " 'neural network (self -supervised).  Example:  An ',\n",
       " 'archaeologist discovers a human skeleton and has to ',\n",
       " 'determine whether it belonged to man or woman. In doing ',\n",
       " 'this, the archaeologist is guided by many past ex amples of ',\n",
       " 'male and female skeletons. Examination of these past ',\n",
       " 'examples (called the training set) allows the archaeologist ',\n",
       " 'to learn about the distinctions between male and female ',\n",
       " 'skeletons. This learning process is an example of supervised ',\n",
       " 'learning, and th e result of learning process can be applied to ',\n",
       " 'determine whether the newly discovered skeleton belongs to ',\n",
       " 'man or woman.  ',\n",
       " ' ',\n",
       " 'Fig. 5 Supervised Learning  ',\n",
       " '2 .Unsupervised Learning  ',\n",
       " 'Unsupervised learning  or Self -organization in which an ',\n",
       " '(output) unit is trained to  respond to clusters of pattern ',\n",
       " 'within the input. In this paradigm the system is supposed to ',\n",
       " 'discover statistically salient features of the input population. ',\n",
       " 'Unlike the supervised learning paradigm, there is no a priori ',\n",
       " 'set of categories into which the pat terns are to be classified; ',\n",
       " 'rather the system must develop its own representation of the ',\n",
       " 'input stimuli. Example:  In a different situation, the ',\n",
       " 'archaeologist has to determine whether a set of skeleton ',\n",
       " 'fragments belong to the same dinosaur species or need to  be ',\n",
       " 'differentiated into different species. For this task, no ',\n",
       " 'previous data may be available to clearly identify the ',\n",
       " 'species for each skeleton fragment. The archaeologist has to ',\n",
       " 'determine whether the skeletons (that can be reconstructed ',\n",
       " 'from the fragments) are sufficiently similar to belong to the ',\n",
       " 'same species, or if the differences between these skeletons ',\n",
       " 'are large enough to warrant grouping them into different ',\n",
       " 'species. This is an unsupervised learning process, which ',\n",
       " 'involves estimating the magnitudes of di fferences between ',\n",
       " 'the skeletons. One archaeologist may believe the skeletons ',\n",
       " 'belong to different species, while another may disagree, and ',\n",
       " 'there is no absolute criterion to determine who is correct.    ',\n",
       " ' 3 .Reinforced Learning  ',\n",
       " 'Reinforcement Learning  is type of learning may be ',\n",
       " 'considered as an intermediate form of the above two types ',\n",
       " 'of learning. Here the learning machine does some action on ',\n",
       " 'the environment and gets a feedback response from the ',\n",
       " 'environment.  The learning system grades its action good ',\n",
       " '(rewarding ) or bad (punishable) based on the environmental ',\n",
       " 'response and accordingly adjusts its parameters. Generally, ',\n",
       " 'parameter adjustment is continued until an equilibrium state ',\n",
       " 'occurs, following which there will be       no more changes ',\n",
       " 'in its parameters. The sel f organizing neural learning may ',\n",
       " 'be categorized under this type of learning. [ 7] ',\n",
       " 'D. Back Propagation Network  ',\n",
       " 'The back propagation algorithm (Rumelhart and ',\n",
       " 'McClelland, 1986) is used in  layered feed -forward ANNs. ',\n",
       " 'This means that the artificial neurons are  organized in ',\n",
       " 'layers,  and send their signals “forward”, and then the errors ',\n",
       " 'are propagated backwards. The network receives inputs by ',\n",
       " 'neurons in the input layer , and the output of the network is ',\n",
       " 'given  by the neurons on an output layer . There may be one ',\n",
       " 'or m ore intermediate hidden layers . The back propagation ',\n",
       " 'algorithm uses supervised learning, which means that we ',\n",
       " 'provide the  algorithm with examples of the inputs and ',\n",
       " 'outputs we want the network to compute, and  then the error ',\n",
       " '(difference between actual and exp ected results) is ',\n",
       " 'calculated. The idea of  the back propagation algorithm is to ',\n",
       " 'reduce this error, until the ANN learns the training  data. ',\n",
       " 'The training begins with random weights, and the goal is to ',\n",
       " 'adjust them so that the  error will be minimal.  [9] Back ',\n",
       " 'propagation network has gained importance due to the ',\n",
       " 'shortcomings of other available networks. The network is a ',\n",
       " 'multi layer network (multi layer perception) that contains at ',\n",
       " 'least one hidden layer in addition to input and output layers. ',\n",
       " 'Number of hidden laye rs & numbers of neurons in each ',\n",
       " 'hidden layer is to be fixed based on application, the ',\n",
       " 'complexity of the problem and the number of inputs and ',\n",
       " 'outputs. Use of non -linear log -sigmoid transfer function ',\n",
       " 'enables the network to simulate non -linearity in practical  ',\n",
       " 'systems. Due to this numerous advantages, back ',\n",
       " 'propagation network is chosen for present work.  [3] ',\n",
       " 'Implementation of back propagation model consists of two ',\n",
       " 'phases. First phase is known as training while the second ',\n",
       " 'phase is called Testing. Training, in bac k propagation is ',\n",
       " 'based on gradient decent rule that tends to adjust weights ',\n",
       " 'and reduce system error in the network. Input layer has ',\n",
       " 'neurons equal in number to that of the inputs. Similarly, ',\n",
       " 'output layer neurons are same in the number as number of ',\n",
       " 'outputs. Number of hidden layer neurons is deciding by trial ',\n",
       " 'and error method using the experimental data. [ 10] ',\n",
       " 'E.ANN Development & Implementation  ',\n",
       " 'In this work, both ANN implementation & training is ',\n",
       " 'developed, using the neural network toolbox of Mat Lab. ',\n",
       " 'Different ANNs are build rather than using one large ANN ',\n",
       " 'including all the output variables. This strategy allowed for ',\n",
       " 'better adjustment of the ANN for each specific problem, ',\n",
       " 'including the optimization of the architecture for each ',\n",
       " 'output.   .   ',\n",
       " ' ',\n",
       " '      ',\n",
       " '         ISSN: 2277 -3754   ',\n",
       " '    ISO 9001:2008 Certified  ',\n",
       " 'International Journal of Engineering and Innovative Technology (IJEIT)  ',\n",
       " 'Volume 2, Issue 1, July 2012  ',\n",
       " ' 193 ',\n",
       " 'F. ANN Training & Predicti on quality  ',\n",
       " 'One of the most relevant aspects of a neural network is ',\n",
       " 'its ability to generalize, that is, to predict cases that are not ',\n",
       " 'included in the training set. One of the problems that occur ',\n",
       " 'during neural network training is called over fitting. The ',\n",
       " 'error on the training set is driven to a very small value, but ',\n",
       " 'when new data is presented to the network, the error is ',\n",
       " 'large. The network has memorized the training examples, ',\n",
       " 'but it has not learned to generalize to new situations. One ',\n",
       " 'method for improving net work generalization is to use a ',\n",
       " 'network that is just large enough to provide an adequate fit. ',\n",
       " 'The larger network you use the more complex functions the ',\n",
       " 'network can create. There are two other methods for ',\n",
       " 'improving generalization that are implemented in Mat  Lab ',\n",
       " 'Neural Network Toolbox software: regularization & early ',\n",
       " 'stopping.  The typical performance function used for ',\n",
       " 'training feed forward neural networks is the mean sum o f ',\n",
       " 'squares of the network errors,  ',\n",
       " '             (2) ',\n",
       " 'It is possible to improve generalizat ion, if you modify the ',\n",
       " 'performance function by adding a term that consists of the ',\n",
       " 'mean of the sum of the squares of the network weights & ',\n",
       " 'biases,  ',\n",
       " 'msereg = λmse +(1 -λ)msw,                                       (3)    ',\n",
       " 'Where λ  is the performance ratio, &  ',\n",
       " '                                              (4)  ',\n",
       " 'Using this performance function causes the network to have ',\n",
       " 'smaller weights & biases, & this force t he network response ',\n",
       " 'to be smoother & less likely to over fit.  Once the different ',\n",
       " 'stages of the training process & the ANN structure had been ',\n",
       " 'determined, & before the optimization procedure is ',\n",
       " 'developed, it is important to estimate the ANN prediction ',\n",
       " 'qualit ies. There is excellent agreement of predicted values ',\n",
       " '& expected values. This close agreement shows that the ',\n",
       " 'ANN can be used in the data analysis, of theoretical work to ',\n",
       " 'generate the missing data in the theoretical program. The ',\n",
       " 'results of model ANN are com pared with the hydrodynamic ',\n",
       " 'simulation data. [ 6] ',\n",
       " 'V. ANN FOR HYDRODYNAMIC JOURNAL ',\n",
       " 'BEARING  ',\n",
       " 'The Artificial Neural Network can be used for prediction ',\n",
       " 'of pressure distribution in hydrodynamic journal bearing ',\n",
       " 'which can be further used for stability analysis of ',\n",
       " 'hydrodynamic journal bearing.  [11]. ',\n",
       " ' ',\n",
       " 'VI. CONCLUSION  ',\n",
       " 'As the ANN is an emerging technology it can be used for ',\n",
       " 'data analysis in applications such as pattern recognition, ',\n",
       " 'prediction, system identification & control. From above ',\n",
       " 'theories it can be seen that ANN i s a radial basis function back propagation network. The network is capable of ',\n",
       " 'predicting the parameters by experimental system. The ',\n",
       " 'network has parallel structure and fast learning capacity. ',\n",
       " 'The collected experimental data such as speed, load, & ',\n",
       " 'values of pressure distribution  etc. are also employed as ',\n",
       " 'training and testing data for an artificial neural network. ',\n",
       " 'The neural network is a feed forward three layered network. ',\n",
       " 'Quick propagation algorithm is used to update the weight of ',\n",
       " 'the network during the train ing. The ANN has a superior ',\n",
       " 'performance to follow the desired results of the system and ',\n",
       " 'is employed to analyze such systems parameters in practical ',\n",
       " 'applications.    ',\n",
       " 'VII. ACKNOWLEDGEMENT  ',\n",
       " 'The authors would like to acknowledge & thanks to Dr. ',\n",
       " 'Y.R. Kharde , Principal, and Shree . Saibaba Institute of ',\n",
       " 'Engineering Research  & Allied Sciences , Rahata, Prof. S.B. ',\n",
       " 'Belkar, Asso. Prof., P.R.E.C. Loni & Prof. R.R. Navthar, ',\n",
       " 'Asstt. Prof., P.D.V.V.P. COE Ahmednagar for their ',\n",
       " 'immense help in this work.  ',\n",
       " ' ',\n",
       " 'REFERENCES  ',\n",
       " '[1] A.O. Kurban , “Analysis of shafts surface pressures   using ',\n",
       " 'neural network”,  Industrial Lubrication and Tribology, ',\n",
       " '(2004), Volume 56, No. 4, Page no. 217 -225. ',\n",
       " '[2] Fazil Canbulut, Cem Sinanoglu and Sahin Yildirim, “Neural ',\n",
       " 'network analysis of leakage oil quantity in the des ign of ',\n",
       " 'partially hydrostatic slipper bearings”,  Industrial Lubrication ',\n",
       " 'and Tribology, (2004), Volume 56, No. 4, Page no. 231 -243 ',\n",
       " '[3] Dr. R. R. Srikanth. “Application of ANN in Condition ',\n",
       " 'Monitoring: A Case Study”, (Conference proceeding ',\n",
       " '“Condition Monitoring of  Mechanical System”) (2009), ',\n",
       " 'Gitam University, Vishakhapattanam, Page no. 31 -44. ',\n",
       " '[4] R.R.Navthar & Dr. N.V. Halegowda, “Analysis of oil film ',\n",
       " 'thickness in Hydrodynamic Journal Bearing using Artificial ',\n",
       " 'Neural Networks”, Ciit International Journal of Artificial ',\n",
       " 'Intelligent System & Machine Learning (Nov. 2011), Volume ',\n",
       " '3, No.12, Page no. -762-766 ',\n",
       " '[5] M. Ananda Rao & J. Srinivas, “Dynamics of rotors supported ',\n",
       " 'on fluid film bearings using neural networks”,  Centre for ',\n",
       " 'System Dynamics & Condition Monitoring & Diagnostic ',\n",
       " 'Studies, Page no.149 -155 ',\n",
       " '[6] Ghorbanian, M. Ahmadi, R. Soltani, “Design predictive tool ',\n",
       " '& optimization of journal bearing using neural network ',\n",
       " 'model & multi objective genetic algorithm”, Scientia Iranica ',\n",
       " 'B (2011), Volume 18, No.5 Page no. -1095 -1105  ',\n",
       " '[7] “Neural netwo rks: A requirement for intelligent systems”  ',\n",
       " '[8] Kishan Mehrotra, Chilkuri K. Mohan, Sanjay Ranka, ',\n",
       " '“Elements of Artificial Neural Networks”, Penram ',\n",
       " 'International Publishing (India), (1997), Volume 1, Page no. -',\n",
       " '1-41.  ',\n",
       " '[9] Carlos Gershenson, ”Artificial Neural Network  for ',\n",
       " 'Beginners”  ',\n",
       " '[10] R.R.Navthar & Dr. N.V. Halegowda, “Applications of ',\n",
       " 'Artificial Neural Network in Pressure Distribution Analysis ',\n",
       " 'of Hydrodynamic Journal Bearings”,  ASME Digital Library, ',\n",
       " 'e-books , International Conference on Computer Technology  ',\n",
       " ' ',\n",
       " '      ',\n",
       " '         ISSN: 2277 -3754   ',\n",
       " '    ISO 9001:2008 Certified  ',\n",
       " 'International Journal of Engineering and Innovative Technology (IJEIT)  ',\n",
       " 'Volume 2, Issue 1, July 2012  ',\n",
       " ' 194 ',\n",
       " '& Development ( 2011),  (Third ICCTD 2011) , Page no. -',\n",
       " '717-722 ',\n",
       " '[11] R.R.Navthar & Dr. N.V. Halegowda, “Pressure  Distribution ',\n",
       " 'Analysis of Hydrodynamic Journal Bearings using Artificial ',\n",
       " 'Neural Network”,  ASME Digital Library, e-books , ',\n",
       " 'International Conference on Computer & Autom ation ',\n",
       " 'Engineering, (Fourth ICCAE 2012), Page no. -153-161 ',\n",
       " ' ',\n",
       " 'AUTHOR BIOGRAPHY  ',\n",
       " ' ',\n",
       " 'Prof.A.D. Dongare  ',\n",
       " 'M.E. (Design Engg), Ph.D.(App)  ',\n",
       " 'P.R.E.C. Loni Rahata Ahmednagar.  ',\n",
       " 'Area of Research:  Design and Tribology.  ',\n",
       " 'Professional Membership: IE (I).  ',\n",
       " ' ',\n",
       " ' Prof.R.R. Kharde  ',\n",
       " 'M.E. (Tribology), Head, Dept. of ',\n",
       " 'Mechanical Engineering.  ',\n",
       " 'P.R.E.C. Loni Rahata Ahmednagar.  ',\n",
       " 'Area of Research:  Design and Tribology.  ',\n",
       " 'Professional Membership: IE (I).  ',\n",
       " ' ',\n",
       " ' ',\n",
       " 'A.D. Kachare  ',\n",
       " 'B.E. (Mechanical), P.G. Student.  ',\n",
       " 'P.R.E.C. Loni Rahata Ahmednagar.  ',\n",
       " 'Area of Research:  Design.  ',\n",
       " 'Professional Membership:  IE (I).  ',\n",
       " ' ',\n",
       " '  ',\n",
       " ' ',\n",
       " '']"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_list = text.split('\\n')\n",
    "print('Number of sentences:', len(text_list), end='\\n\\n')\n",
    "[i for i in text_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(txt: list[str]):\n",
    "    temp = []\n",
    "    for i in txt:\n",
    "        if not i.isspace():\n",
    "            temp.append(i.strip().lower())\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences: 525\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['issn: 2277 -3754',\n",
       " 'iso 9001:2008 certified',\n",
       " 'international journal of engineering and innovative technology (ijeit)',\n",
       " 'volume 2, issue 1, july 2012',\n",
       " '189',\n",
       " 'introduction to artificial neural network',\n",
       " 'a.d.dongare, r.r.kharde, amit d.kachare',\n",
       " 'abstract : - this paper presents an emergence of an artificial',\n",
       " 'neural network (ann) as a tool for analysis of different',\n",
       " 'parameters of a system. an artificial neural network (ann) is',\n",
       " 'an information -processing paradigm that is inspired by the way',\n",
       " 'biological nervous systems such as brain, process information.',\n",
       " 'ann consists of multiple layers of simple processing elements',\n",
       " 'called as neurons. the neuron performs two functions, namel y,',\n",
       " 'collection of inputs & generation of an output. use of ann',\n",
       " 'provides overview of the theory, learning rules, and applications',\n",
       " 'of the most important neural network models, definitions and',\n",
       " 'style of computation . the mathematical model of network',\n",
       " 'throws the light on the concept of inputs, weights, summing',\n",
       " 'function, activation function & outputs. then ann helps to',\n",
       " 'decide the type of learning for  adjustment of weights with',\n",
       " 'change in parameters. finally the analysis of a system is',\n",
       " 'completed by ann implementation  & ann training & prediction',\n",
       " 'quality.',\n",
       " 'keywords:  biological inspiration,  ann methodology, ann',\n",
       " 'implementation and prediction.',\n",
       " 'i. introduction',\n",
       " 'many tasks involving intelligence or pattern recognition',\n",
       " 'are extremely difficult to automate, but appear to be',\n",
       " 'perfor med very easily by humans. for instance, human s',\n",
       " 'recognize various objects and make sense out of the large',\n",
       " 'amount of visual information in their surroundings,',\n",
       " 'apparently requiring very little effort. it stands to reason',\n",
       " 'that computing systems that attempt s imilar tasks will profit',\n",
       " 'enormou sly from understanding how human s perform these',\n",
       " 'tasks, and simulating these processes to the extent allowed',\n",
       " 'by physical limitations. this necessitates the study and',\n",
       " 'simulation of neural networks.  the neural network of an',\n",
       " 'human is part of its nervous system, containing a large',\n",
       " 'number of interconnected neurons (nerve cells). “neural” is',\n",
       " 'an adjective for neuron, and “network” denotes a graph like',\n",
       " 'structure. artificial neural network refers to computing',\n",
       " 'systems whose central them e is borrowed from the analogy',\n",
       " 'of biological neural networks.  artificial neural networks',\n",
       " 'are also referred to as “neural nets”, artificial neural',\n",
       " 'systems “parallel distributed processing systems” and',\n",
       " '“connectionist systems”. for a computing system to be',\n",
       " 'called by these pretty names, it is necessary for the system',\n",
       " 'to have a labeled directed graph structure where nodes',\n",
       " 'perform some simple computations. from elementary graph',\n",
       " 'theory we recall that a “directed graph” consists of a set of',\n",
       " '“nodes”  (vertices) and  a set of “connections”',\n",
       " '(edges/links/arcs) connecting pairs of nodes. in a neural',\n",
       " 'network, each node performs some simple computations,',\n",
       " 'and each connection conveys a signal from one node to',\n",
       " 'another, labeled by a number called the “connection',\n",
       " 'strength” or “ weight” indicating the extent to which a',\n",
       " 'signal is amplified or diminished by connection. this',\n",
       " 'system is the alternative for human expertise and knowledge. artificial neural networks are modeled closely',\n",
       " 'following the brain and therefore a great deal of',\n",
       " 'terminology is borrowed from neuroscience.',\n",
       " 'ii. literature review',\n",
       " 'a.o. kurban investigated an artificial neural network are',\n",
       " 'non-linear mapping systems with a structure loosely based',\n",
       " 'on principles observed in the biological nervous systems. in',\n",
       " 'greatly simplified t erms from, a typical real neuron has a',\n",
       " 'branching dentritic tree that collects signals from many',\n",
       " 'other neurons in a limited area; a cell body that integrates',\n",
       " 'collected signals and generates a response signal (as well as',\n",
       " 'manages metabolic functions); and alo ng branching axon',\n",
       " 'that distributes the response through contacts with dentritic',\n",
       " 'trees of many other neurons. the response of each neuron is',\n",
       " 'a relatively simple non -linear function of its inputs and is',\n",
       " 'largely determined by the strengths of the connections from',\n",
       " 'its inputs. in spite of the relative simplicity of the individual',\n",
       " 'units, systems containing many neurons can generate',\n",
       " 'complex and intersecting behaviors. in general terms, a nn',\n",
       " 'consists of large number of simple processors linked by',\n",
       " 'weighted connectio ns. by analogy, the processing nodes',\n",
       " 'may be called “neurons”. each node output depends only on',\n",
       " 'the information that is locally available at the node, either',\n",
       " 'stored internally or arriving via the weighted connections.',\n",
       " 'each unit receives inputs from many oth er nodes and',\n",
       " 'transmits its output to other nodes. by itself, a single',\n",
       " 'processing element is not very powerful; it generates a',\n",
       " 'scalar output with a single numerical value, which is a',\n",
       " 'simple non -linear function of its inputs. the power of the',\n",
       " 'system emerges from the combination of many units in an',\n",
       " 'appropriate way. a network is utilized different function by',\n",
       " 'varying the connection topology and the values of the',\n",
       " 'connecting weights. complex functions can be implemented',\n",
       " 'by connecting the units together with appro priate weights. it',\n",
       " 'has been shown that a sufficiently large network with an',\n",
       " 'appropriate structure and property chosen weights can',\n",
       " 'approximate with arbitrary accuracy any function satisfy ing',\n",
       " 'certain broad constraints. [1 ] this model is a drastically',\n",
       " 'simplif ied approximation of real nervous systems. the',\n",
       " 'intent is to capture the major characteristics important in the',\n",
       " 'information processing functions of real networks without',\n",
       " 'varying too much about the physical constraints imposed by',\n",
       " 'biology. artificial nn are m ade up of simple, highly',\n",
       " 'interconnected processing units called neurons, each of',\n",
       " 'which performs two functions, namely, aggregation of its',\n",
       " 'inputs from other neurons or the external environment and',\n",
       " 'generation of an output from the aggregated inputs.',\n",
       " 'through this simple structure, neural networks have been',\n",
       " 'shown to be able to approximate most continuous functions',\n",
       " 'to any degree of accuracy, by choice of an appropriate',\n",
       " 'issn: 2277 -3754',\n",
       " 'iso 9001:2008 certified',\n",
       " 'international journal of engineering and innovative technology (ijeit)',\n",
       " 'volume 2, issue 1, july 2012',\n",
       " '190',\n",
       " 'number of neuron units (kurban and yildirim, 2003;',\n",
       " 'yildirim and uzmay, 2003) . [2]',\n",
       " 'iii. biolog ical inspiration',\n",
       " 'human brain is made up of a network of neurons that are',\n",
       " 'coupled with receptors and effectors. receptors are called',\n",
       " '“dendrites” and effectors are called “axons” .[3] fig. 1',\n",
       " 'shows that the dendrites collects the signals from many',\n",
       " 'other neuron s in a limited area; a cell body  or soma that',\n",
       " 'integrates collected signals & generates a response signal &',\n",
       " 'along branching axon that distributes the response through',\n",
       " 'contacts with dendrite trees  of many other neurons. [4]',\n",
       " 'fig. 1 biological neuron',\n",
       " 'iv. a nn methodology',\n",
       " 'anns  are basically massive parallel computational',\n",
       " 'models that imitate the function of human brain. an ann',\n",
       " 'consists of large number of simple processors linked by',\n",
       " 'weighted connections. by analogy, the processing nodes',\n",
       " 'may be called “neurons”.  each node output depends only on',\n",
       " 'the information that is locally available at the node, either',\n",
       " 'stored internally or arriving via the weighted connections.',\n",
       " 'each unit receives inputs from many other nodes transmits',\n",
       " 'its output to yet another nodes. by itself , a single processing',\n",
       " 'element is not very powerful; it generates a scalar output',\n",
       " 'with single numerical value, which is a simple non -linear',\n",
       " 'function of its inputs. the power of the system emerges from the combination of many units in an appropriate way.',\n",
       " '[1] the ann does not really solve the problem in a strictly',\n",
       " 'mathematical sense, but it demonstrates information',\n",
       " 'processing characteristics that give an approximate solution',\n",
       " 'to a given problem. the anns have been widely used in',\n",
       " 'complex non linear function mapp ing, image processing,',\n",
       " 'pattern recogni tion & classification & so on. feed -forward',\n",
       " 'networks are common type of neural networks. a feed',\n",
       " 'forward network comprises an input layer, where the inputs',\n",
       " 'of the problem are received, hidden layers, where the',\n",
       " 'relations hip between the inputs & outputs are determined &',\n",
       " 'represented by synaptic weights, & an output layer which',\n",
       " 'emits the outputs of the problem. the neural feed forward',\n",
       " 'network is modeled with three basic elements:  a) a set of',\n",
       " 'synapses characterized by synapti c weights,  b) an adder or',\n",
       " 'linear combiner for summing the input signals.  c) an',\n",
       " 'activation function for limiting the amplitude of the output',\n",
       " 'of neuron to some finite value. the input of the activation',\n",
       " 'function can be increased by using a bias term. here, we',\n",
       " 'have made use of a certain ann architecture known as the',\n",
       " 'multi -layer -feed-forward neural network or multi layer',\n",
       " 'perceptron (mlp) [5] .',\n",
       " 'fig.2 style of neural computation',\n",
       " 'in above fig.2 a n input is presented to the neural network',\n",
       " 'and a corresponding desire d or target response set at the',\n",
       " 'output (when this is the case the training is called',\n",
       " 'supervised). an error is composed from the difference',\n",
       " 'between the desired response and the system output. this',\n",
       " 'error information is fed back to the system and adjusts the',\n",
       " 'system parameters in a systematic fashion (the learning',\n",
       " 'rule). the process is repeated until the performance is',\n",
       " 'acceptable. it is clear from this description that the',\n",
       " 'performance hinges heavily on the data. if one does not',\n",
       " 'have data that cover a significan t portion of the operating',\n",
       " 'conditions or if they are noisy, then neural network',\n",
       " 'technology is probably not the right solution. on the other',\n",
       " 'hand, if there is plenty of data and the problem is poorly',\n",
       " 'understood to derive an approximate model, then neural',\n",
       " 'network technology is a good choice. this operating',\n",
       " 'procedure should be contrasted with the traditional',\n",
       " 'engineering design, made of exhaustive subsystem',\n",
       " 'specifications and intercommunication protocols. in artificial neural networks, the desig ner chooses the network',\n",
       " 'topology, the performance function, the learning rule, and',\n",
       " 'the criterion to stop the training phase, but the system',\n",
       " 'automatically adjusts the parameters. so, it is difficult to',\n",
       " 'bring a priori information into the design, and when the',\n",
       " 'system does no t work properly it is also hard to',\n",
       " 'incrementally refine the solution. but ann -based solutions',\n",
       " 'are extremely efficient in terms of development time and',\n",
       " 'resources, and in many difficult problems artificial neural',\n",
       " 'networks provide performance that is difficul t to match with',\n",
       " 'other technologies. denker 10 years ago said that \"artificial',\n",
       " 'neural networks are the second best way to implement a',\n",
       " 'solution\" motivated by the simplicity of their design and',\n",
       " 'because of their universality, only shadowed by the',\n",
       " 'traditional d esign obtained by studying the physics of the',\n",
       " 'problem. at present, artificial neural networks are emerging',\n",
       " 'as the technology of choice for many applications, such as',\n",
       " 'pattern recognition, prediction, system identification, and',\n",
       " 'control.[ 6]',\n",
       " 'issn: 2277 -3754',\n",
       " 'iso 9001:2008 certified',\n",
       " 'international journal of engineering and innovative technology (ijeit)',\n",
       " 'volume 2, issue 1, july 2012',\n",
       " '191',\n",
       " 'table 1. terminolo gy of neuron',\n",
       " 'biological terminology  ann terminology',\n",
       " 'neuron  node/unit/cell/neurode',\n",
       " 'synapse  connection/edge/link',\n",
       " 'synaptic efficiency  connection strength/weight',\n",
       " 'firing frequency  node output',\n",
       " 'a. mathematical model',\n",
       " 'when creating a functional model of t he biological',\n",
       " 'neuron, there are three basic components of importance.',\n",
       " 'first, the synapses of the neuron are modeled as weights.',\n",
       " 'the strength of the connection between an input and a',\n",
       " 'neuron is noted by the value of the weight. negative weight',\n",
       " 'values reflect  inhibitory connections, while positive values',\n",
       " 'designate excitatory connections [haykin]. the next two',\n",
       " 'components model the actual activity within the neuron cell.',\n",
       " 'an adder sums up all the inputs modified by their respective',\n",
       " 'weights. this activity is refer red to as linear combination.',\n",
       " 'finally, an activation function controls the amplitude of the',\n",
       " 'output of the neuron. an acceptable range of output is',\n",
       " 'usually between 0 and 1, or -1 and 1.  mathematically, this',\n",
       " 'process is described in the figure,',\n",
       " 'fig. 3 math ematical model',\n",
       " 'from this model the interval activity of the neuron can be',\n",
       " 'shown to be,',\n",
       " '(1)',\n",
       " 'the output of the neuron, yk, would therefore be the',\n",
       " 'outcome of some activation function on the value of vk. [ 7]',\n",
       " 'b. feed f orward networks',\n",
       " 'this is a subclass of acrylic networks in which a',\n",
       " 'connection is allowed from a node in layer i only to nodes',\n",
       " 'in layer i+1 as shown in fig.4 . these networks are',\n",
       " 'succinctly described by a sequence of numbers indicating',\n",
       " 'the number of nodes in each layer. for instance, the network shown in fig. 4 is a 3 -2-3-2 feed forward network;',\n",
       " 'it contains three nodes in the input layer (layer 0), two',\n",
       " 'nodes in the first hidden layer (layer 1), three nodes in the',\n",
       " 'second hidden layer (layer 2), and two nodes in  the output',\n",
       " 'layer (layer 3).  these networks, generally with no more',\n",
       " 'than four such layers, are among the most common neural',\n",
       " 'nets in use, so much so that some users identify the phrase',\n",
       " '“neural networks” to mean only feed forward networks.',\n",
       " 'conceptually, node s in successively higher layers abstract',\n",
       " 'successively higher level features from preceding layers. in',\n",
       " 'the literature on neural networks, the term “feed forward”',\n",
       " 'has been used sometimes to refer to layered or acrylic',\n",
       " 'networks. [ 8]',\n",
       " 'fig. 4 feed forwa rd networks',\n",
       " 'c. neural learning',\n",
       " 'it is reasonable to conjecture that neurons in an animal’s',\n",
       " 'brain are “hard wired.” it is equally obvious that animals,',\n",
       " 'especially the higher order animals, learn as they grow.',\n",
       " 'how does this learning occur? what are possible',\n",
       " 'mathematical models of learning?  in this section, we',\n",
       " 'summarize some of the basic theories of biological learning',\n",
       " 'and their adaptations for artificial neural networks. in',\n",
       " 'artificial neural networks, learning refers to the method of',\n",
       " 'modifying the weights of c onnections between the nodes of',\n",
       " 'a specified network.  learning is the process by which the',\n",
       " 'random -valued parameters (weights and bias) of a neural',\n",
       " 'network are adapted through a continuous process of',\n",
       " 'simulation by the environment in which network is',\n",
       " 'embedded . learning rate is defined as the rate at which',\n",
       " 'network gets adapted. type of learning is determined by the',\n",
       " 'manner in which parameter change takes place. learning',\n",
       " 'may be categorized as supervised learning, unsupervised',\n",
       " 'learning and r einforced learning.  in supervised learning,  a',\n",
       " 'teacher is available to indicate whether a system is',\n",
       " 'performing correctly, or to indicate a desired response, or to',\n",
       " 'validate the acceptability of a system’s responses, or to',\n",
       " 'indicate the amount of error in system performance. this is',\n",
       " 'in contrast with unsupervised learning, where no teacher is',\n",
       " 'available and learning must rely on guidance obtained',\n",
       " 'heuristically by the system examining different sample data',\n",
       " 'or the environment. learning is similar to training i.e. one',\n",
       " 'has to learn somethi ng which is analogous to one has to be',\n",
       " 'trained. a neural network has to be configured such that the',\n",
       " \"application of a set of inputs produces (either 'direct' or via\",\n",
       " 'a relaxation process) the desired set of outputs. various',\n",
       " 'methods to set the strengths of th e connections exist. one',\n",
       " 'way is to set the weights explicitly, using a priori',\n",
       " 'issn: 2277 -3754',\n",
       " 'iso 9001:2008 certified',\n",
       " 'international journal of engineering and innovative technology (ijeit)',\n",
       " 'volume 2, issue 1, july 2012',\n",
       " '192',\n",
       " \"knowledge. another way is to 'train' the neural network by\",\n",
       " 'feeding it teaching patterns and letting it change its weights',\n",
       " 'according to some learning rule. we  can categorize the',\n",
       " 'learning situations in two distinct sorts. these are',\n",
       " '1. supervised learning',\n",
       " 'supervised learning  or associative learning in which the',\n",
       " 'network is trained by providing it with input and matching',\n",
       " 'output patterns. these input -output pairs can be provided by',\n",
       " 'an external teacher, or by the system which contains the',\n",
       " 'neural network (self -supervised).  example:  an',\n",
       " 'archaeologist discovers a human skeleton and has to',\n",
       " 'determine whether it belonged to man or woman. in doing',\n",
       " 'this, the archaeologist is guided by many past ex amples of',\n",
       " 'male and female skeletons. examination of these past',\n",
       " 'examples (called the training set) allows the archaeologist',\n",
       " 'to learn about the distinctions between male and female',\n",
       " 'skeletons. this learning process is an example of supervised',\n",
       " 'learning, and th e result of learning process can be applied to',\n",
       " 'determine whether the newly discovered skeleton belongs to',\n",
       " 'man or woman.',\n",
       " 'fig. 5 supervised learning',\n",
       " '2 .unsupervised learning',\n",
       " 'unsupervised learning  or self -organization in which an',\n",
       " '(output) unit is trained to  respond to clusters of pattern',\n",
       " 'within the input. in this paradigm the system is supposed to',\n",
       " 'discover statistically salient features of the input population.',\n",
       " 'unlike the supervised learning paradigm, there is no a priori',\n",
       " 'set of categories into which the pat terns are to be classified;',\n",
       " 'rather the system must develop its own representation of the',\n",
       " 'input stimuli. example:  in a different situation, the',\n",
       " 'archaeologist has to determine whether a set of skeleton',\n",
       " 'fragments belong to the same dinosaur species or need to  be',\n",
       " 'differentiated into different species. for this task, no',\n",
       " 'previous data may be available to clearly identify the',\n",
       " 'species for each skeleton fragment. the archaeologist has to',\n",
       " 'determine whether the skeletons (that can be reconstructed',\n",
       " 'from the fragments) are sufficiently similar to belong to the',\n",
       " 'same species, or if the differences between these skeletons',\n",
       " 'are large enough to warrant grouping them into different',\n",
       " 'species. this is an unsupervised learning process, which',\n",
       " 'involves estimating the magnitudes of di fferences between',\n",
       " 'the skeletons. one archaeologist may believe the skeletons',\n",
       " 'belong to different species, while another may disagree, and',\n",
       " 'there is no absolute criterion to determine who is correct.',\n",
       " '3 .reinforced learning',\n",
       " 'reinforcement learning  is type of learning may be',\n",
       " 'considered as an intermediate form of the above two types',\n",
       " 'of learning. here the learning machine does some action on',\n",
       " 'the environment and gets a feedback response from the',\n",
       " 'environment.  the learning system grades its action good',\n",
       " '(rewarding ) or bad (punishable) based on the environmental',\n",
       " 'response and accordingly adjusts its parameters. generally,',\n",
       " 'parameter adjustment is continued until an equilibrium state',\n",
       " 'occurs, following which there will be       no more changes',\n",
       " 'in its parameters. the sel f organizing neural learning may',\n",
       " 'be categorized under this type of learning. [ 7]',\n",
       " 'd. back propagation network',\n",
       " 'the back propagation algorithm (rumelhart and',\n",
       " 'mcclelland, 1986) is used in  layered feed -forward anns.',\n",
       " 'this means that the artificial neurons are  organized in',\n",
       " 'layers,  and send their signals “forward”, and then the errors',\n",
       " 'are propagated backwards. the network receives inputs by',\n",
       " 'neurons in the input layer , and the output of the network is',\n",
       " 'given  by the neurons on an output layer . there may be one',\n",
       " 'or m ore intermediate hidden layers . the back propagation',\n",
       " 'algorithm uses supervised learning, which means that we',\n",
       " 'provide the  algorithm with examples of the inputs and',\n",
       " 'outputs we want the network to compute, and  then the error',\n",
       " '(difference between actual and exp ected results) is',\n",
       " 'calculated. the idea of  the back propagation algorithm is to',\n",
       " 'reduce this error, until the ann learns the training  data.',\n",
       " 'the training begins with random weights, and the goal is to',\n",
       " 'adjust them so that the  error will be minimal.  [9] back',\n",
       " 'propagation network has gained importance due to the',\n",
       " 'shortcomings of other available networks. the network is a',\n",
       " 'multi layer network (multi layer perception) that contains at',\n",
       " 'least one hidden layer in addition to input and output layers.',\n",
       " 'number of hidden laye rs & numbers of neurons in each',\n",
       " 'hidden layer is to be fixed based on application, the',\n",
       " 'complexity of the problem and the number of inputs and',\n",
       " 'outputs. use of non -linear log -sigmoid transfer function',\n",
       " 'enables the network to simulate non -linearity in practical',\n",
       " 'systems. due to this numerous advantages, back',\n",
       " 'propagation network is chosen for present work.  [3]',\n",
       " 'implementation of back propagation model consists of two',\n",
       " 'phases. first phase is known as training while the second',\n",
       " 'phase is called testing. training, in bac k propagation is',\n",
       " 'based on gradient decent rule that tends to adjust weights',\n",
       " 'and reduce system error in the network. input layer has',\n",
       " 'neurons equal in number to that of the inputs. similarly,',\n",
       " 'output layer neurons are same in the number as number of',\n",
       " 'outputs. number of hidden layer neurons is deciding by trial',\n",
       " 'and error method using the experimental data. [ 10]',\n",
       " 'e.ann development & implementation',\n",
       " 'in this work, both ann implementation & training is',\n",
       " 'developed, using the neural network toolbox of mat lab.',\n",
       " 'different anns are build rather than using one large ann',\n",
       " 'including all the output variables. this strategy allowed for',\n",
       " 'better adjustment of the ann for each specific problem,',\n",
       " 'including the optimization of the architecture for each',\n",
       " 'output.   .',\n",
       " 'issn: 2277 -3754',\n",
       " 'iso 9001:2008 certified',\n",
       " 'international journal of engineering and innovative technology (ijeit)',\n",
       " 'volume 2, issue 1, july 2012',\n",
       " '193',\n",
       " 'f. ann training & predicti on quality',\n",
       " 'one of the most relevant aspects of a neural network is',\n",
       " 'its ability to generalize, that is, to predict cases that are not',\n",
       " 'included in the training set. one of the problems that occur',\n",
       " 'during neural network training is called over fitting. the',\n",
       " 'error on the training set is driven to a very small value, but',\n",
       " 'when new data is presented to the network, the error is',\n",
       " 'large. the network has memorized the training examples,',\n",
       " 'but it has not learned to generalize to new situations. one',\n",
       " 'method for improving net work generalization is to use a',\n",
       " 'network that is just large enough to provide an adequate fit.',\n",
       " 'the larger network you use the more complex functions the',\n",
       " 'network can create. there are two other methods for',\n",
       " 'improving generalization that are implemented in mat  lab',\n",
       " 'neural network toolbox software: regularization & early',\n",
       " 'stopping.  the typical performance function used for',\n",
       " 'training feed forward neural networks is the mean sum o f',\n",
       " 'squares of the network errors,',\n",
       " '(2)',\n",
       " 'it is possible to improve generalizat ion, if you modify the',\n",
       " 'performance function by adding a term that consists of the',\n",
       " 'mean of the sum of the squares of the network weights &',\n",
       " 'biases,',\n",
       " 'msereg = λmse +(1 -λ)msw,                                       (3)',\n",
       " 'where λ  is the performance ratio, &',\n",
       " '(4)',\n",
       " 'using this performance function causes the network to have',\n",
       " 'smaller weights & biases, & this force t he network response',\n",
       " 'to be smoother & less likely to over fit.  once the different',\n",
       " 'stages of the training process & the ann structure had been',\n",
       " 'determined, & before the optimization procedure is',\n",
       " 'developed, it is important to estimate the ann prediction',\n",
       " 'qualit ies. there is excellent agreement of predicted values',\n",
       " '& expected values. this close agreement shows that the',\n",
       " 'ann can be used in the data analysis, of theoretical work to',\n",
       " 'generate the missing data in the theoretical program. the',\n",
       " 'results of model ann are com pared with the hydrodynamic',\n",
       " 'simulation data. [ 6]',\n",
       " 'v. ann for hydrodynamic journal',\n",
       " 'bearing',\n",
       " 'the artificial neural network can be used for prediction',\n",
       " 'of pressure distribution in hydrodynamic journal bearing',\n",
       " 'which can be further used for stability analysis of',\n",
       " 'hydrodynamic journal bearing.  [11].',\n",
       " 'vi. conclusion',\n",
       " 'as the ann is an emerging technology it can be used for',\n",
       " 'data analysis in applications such as pattern recognition,',\n",
       " 'prediction, system identification & control. from above',\n",
       " 'theories it can be seen that ann i s a radial basis function back propagation network. the network is capable of',\n",
       " 'predicting the parameters by experimental system. the',\n",
       " 'network has parallel structure and fast learning capacity.',\n",
       " 'the collected experimental data such as speed, load, &',\n",
       " 'values of pressure distribution  etc. are also employed as',\n",
       " 'training and testing data for an artificial neural network.',\n",
       " 'the neural network is a feed forward three layered network.',\n",
       " 'quick propagation algorithm is used to update the weight of',\n",
       " 'the network during the train ing. the ann has a superior',\n",
       " 'performance to follow the desired results of the system and',\n",
       " 'is employed to analyze such systems parameters in practical',\n",
       " 'applications.',\n",
       " 'vii. acknowledgement',\n",
       " 'the authors would like to acknowledge & thanks to dr.',\n",
       " 'y.r. kharde , principal, and shree . saibaba institute of',\n",
       " 'engineering research  & allied sciences , rahata, prof. s.b.',\n",
       " 'belkar, asso. prof., p.r.e.c. loni & prof. r.r. navthar,',\n",
       " 'asstt. prof., p.d.v.v.p. coe ahmednagar for their',\n",
       " 'immense help in this work.',\n",
       " 'references',\n",
       " '[1] a.o. kurban , “analysis of shafts surface pressures   using',\n",
       " 'neural network”,  industrial lubrication and tribology,',\n",
       " '(2004), volume 56, no. 4, page no. 217 -225.',\n",
       " '[2] fazil canbulut, cem sinanoglu and sahin yildirim, “neural',\n",
       " 'network analysis of leakage oil quantity in the des ign of',\n",
       " 'partially hydrostatic slipper bearings”,  industrial lubrication',\n",
       " 'and tribology, (2004), volume 56, no. 4, page no. 231 -243',\n",
       " '[3] dr. r. r. srikanth. “application of ann in condition',\n",
       " 'monitoring: a case study”, (conference proceeding',\n",
       " '“condition monitoring of  mechanical system”) (2009),',\n",
       " 'gitam university, vishakhapattanam, page no. 31 -44.',\n",
       " '[4] r.r.navthar & dr. n.v. halegowda, “analysis of oil film',\n",
       " 'thickness in hydrodynamic journal bearing using artificial',\n",
       " 'neural networks”, ciit international journal of artificial',\n",
       " 'intelligent system & machine learning (nov. 2011), volume',\n",
       " '3, no.12, page no. -762-766',\n",
       " '[5] m. ananda rao & j. srinivas, “dynamics of rotors supported',\n",
       " 'on fluid film bearings using neural networks”,  centre for',\n",
       " 'system dynamics & condition monitoring & diagnostic',\n",
       " 'studies, page no.149 -155',\n",
       " '[6] ghorbanian, m. ahmadi, r. soltani, “design predictive tool',\n",
       " '& optimization of journal bearing using neural network',\n",
       " 'model & multi objective genetic algorithm”, scientia iranica',\n",
       " 'b (2011), volume 18, no.5 page no. -1095 -1105',\n",
       " '[7] “neural netwo rks: a requirement for intelligent systems”',\n",
       " '[8] kishan mehrotra, chilkuri k. mohan, sanjay ranka,',\n",
       " '“elements of artificial neural networks”, penram',\n",
       " 'international publishing (india), (1997), volume 1, page no. -',\n",
       " '1-41.',\n",
       " '[9] carlos gershenson, ”artificial neural network  for',\n",
       " 'beginners”',\n",
       " '[10] r.r.navthar & dr. n.v. halegowda, “applications of',\n",
       " 'artificial neural network in pressure distribution analysis',\n",
       " 'of hydrodynamic journal bearings”,  asme digital library,',\n",
       " 'e-books , international conference on computer technology',\n",
       " 'issn: 2277 -3754',\n",
       " 'iso 9001:2008 certified',\n",
       " 'international journal of engineering and innovative technology (ijeit)',\n",
       " 'volume 2, issue 1, july 2012',\n",
       " '194',\n",
       " '& development ( 2011),  (third icctd 2011) , page no. -',\n",
       " '717-722',\n",
       " '[11] r.r.navthar & dr. n.v. halegowda, “pressure  distribution',\n",
       " 'analysis of hydrodynamic journal bearings using artificial',\n",
       " 'neural network”,  asme digital library, e-books ,',\n",
       " 'international conference on computer & autom ation',\n",
       " 'engineering, (fourth iccae 2012), page no. -153-161',\n",
       " 'author biography',\n",
       " 'prof.a.d. dongare',\n",
       " 'm.e. (design engg), ph.d.(app)',\n",
       " 'p.r.e.c. loni rahata ahmednagar.',\n",
       " 'area of research:  design and tribology.',\n",
       " 'professional membership: ie (i).',\n",
       " 'prof.r.r. kharde',\n",
       " 'm.e. (tribology), head, dept. of',\n",
       " 'mechanical engineering.',\n",
       " 'p.r.e.c. loni rahata ahmednagar.',\n",
       " 'area of research:  design and tribology.',\n",
       " 'professional membership: ie (i).',\n",
       " 'a.d. kachare',\n",
       " 'b.e. (mechanical), p.g. student.',\n",
       " 'p.r.e.c. loni rahata ahmednagar.',\n",
       " 'area of research:  design.',\n",
       " 'professional membership:  ie (i).',\n",
       " '']"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_list = clean_text(text_list)\n",
    "print('Number of sentences:', len(text_list), end='\\n\\n')\n",
    "text_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_sentences(txt: list[str]) -> list[str]:\n",
    "\n",
    "    temp = []\n",
    "    \n",
    "    for i in txt:\n",
    "        if i.lower() == 'the authors would like to acknowledge & thanks to dr.':\n",
    "            break\n",
    "        \n",
    "        patterns = [\n",
    "            r\"^[iv]+.\",\n",
    "            r\"issn:.*\",\n",
    "            r\"iso.*certified$\",\n",
    "            r\"international journal of engineering and innovative technology \\(ijeit\\)\",\n",
    "            r\"volume \\d, issue \\d, .+\",\n",
    "            r\"^\\S+$\",\n",
    "            r\"^fig\\.\\s?\\d+.+\",\n",
    "            r\"^table\\s?\\d+\\..+\",\n",
    "            r\"^[a-z]+\\.\",\n",
    "            r\"^\\d+ \\..+\",\n",
    "            r\"^\\d+\\. .+\",\n",
    "        ]\n",
    "        \n",
    "        if any(re.search(pattern, i, re.IGNORECASE) for pattern in patterns):\n",
    "            continue\n",
    "        \n",
    "        temp.append(i)\n",
    "    \n",
    "    return temp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences: 344\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['abstract : - this paper presents an emergence of an artificial',\n",
       " 'neural network (ann) as a tool for analysis of different',\n",
       " 'parameters of a system. an artificial neural network (ann) is',\n",
       " 'an information -processing paradigm that is inspired by the way',\n",
       " 'biological nervous systems such as brain, process information.',\n",
       " 'ann consists of multiple layers of simple processing elements',\n",
       " 'called as neurons. the neuron performs two functions, namel y,',\n",
       " 'collection of inputs & generation of an output. use of ann',\n",
       " 'provides overview of the theory, learning rules, and applications',\n",
       " 'of the most important neural network models, definitions and',\n",
       " 'style of computation . the mathematical model of network',\n",
       " 'throws the light on the concept of inputs, weights, summing',\n",
       " 'function, activation function & outputs. then ann helps to',\n",
       " 'decide the type of learning for  adjustment of weights with',\n",
       " 'change in parameters. finally the analysis of a system is',\n",
       " 'completed by ann implementation  & ann training & prediction',\n",
       " 'keywords:  biological inspiration,  ann methodology, ann',\n",
       " 'many tasks involving intelligence or pattern recognition',\n",
       " 'are extremely difficult to automate, but appear to be',\n",
       " 'perfor med very easily by humans. for instance, human s',\n",
       " 'recognize various objects and make sense out of the large',\n",
       " 'amount of visual information in their surroundings,',\n",
       " 'apparently requiring very little effort. it stands to reason',\n",
       " 'that computing systems that attempt s imilar tasks will profit',\n",
       " 'enormou sly from understanding how human s perform these',\n",
       " 'tasks, and simulating these processes to the extent allowed',\n",
       " 'by physical limitations. this necessitates the study and',\n",
       " 'simulation of neural networks.  the neural network of an',\n",
       " 'human is part of its nervous system, containing a large',\n",
       " 'number of interconnected neurons (nerve cells). “neural” is',\n",
       " 'an adjective for neuron, and “network” denotes a graph like',\n",
       " 'systems whose central them e is borrowed from the analogy',\n",
       " 'of biological neural networks.  artificial neural networks',\n",
       " 'are also referred to as “neural nets”, artificial neural',\n",
       " 'systems “parallel distributed processing systems” and',\n",
       " '“connectionist systems”. for a computing system to be',\n",
       " 'called by these pretty names, it is necessary for the system',\n",
       " 'to have a labeled directed graph structure where nodes',\n",
       " 'perform some simple computations. from elementary graph',\n",
       " 'theory we recall that a “directed graph” consists of a set of',\n",
       " '“nodes”  (vertices) and  a set of “connections”',\n",
       " '(edges/links/arcs) connecting pairs of nodes. in a neural',\n",
       " 'network, each node performs some simple computations,',\n",
       " 'and each connection conveys a signal from one node to',\n",
       " 'another, labeled by a number called the “connection',\n",
       " 'strength” or “ weight” indicating the extent to which a',\n",
       " 'signal is amplified or diminished by connection. this',\n",
       " 'system is the alternative for human expertise and knowledge. artificial neural networks are modeled closely',\n",
       " 'following the brain and therefore a great deal of',\n",
       " 'terminology is borrowed from neuroscience.',\n",
       " 'non-linear mapping systems with a structure loosely based',\n",
       " 'on principles observed in the biological nervous systems. in',\n",
       " 'greatly simplified t erms from, a typical real neuron has a',\n",
       " 'branching dentritic tree that collects signals from many',\n",
       " 'other neurons in a limited area; a cell body that integrates',\n",
       " 'collected signals and generates a response signal (as well as',\n",
       " 'manages metabolic functions); and alo ng branching axon',\n",
       " 'that distributes the response through contacts with dentritic',\n",
       " 'trees of many other neurons. the response of each neuron is',\n",
       " 'a relatively simple non -linear function of its inputs and is',\n",
       " 'largely determined by the strengths of the connections from',\n",
       " 'units, systems containing many neurons can generate',\n",
       " 'complex and intersecting behaviors. in general terms, a nn',\n",
       " 'consists of large number of simple processors linked by',\n",
       " 'weighted connectio ns. by analogy, the processing nodes',\n",
       " 'may be called “neurons”. each node output depends only on',\n",
       " 'the information that is locally available at the node, either',\n",
       " 'stored internally or arriving via the weighted connections.',\n",
       " 'each unit receives inputs from many oth er nodes and',\n",
       " 'transmits its output to other nodes. by itself, a single',\n",
       " 'processing element is not very powerful; it generates a',\n",
       " 'scalar output with a single numerical value, which is a',\n",
       " 'simple non -linear function of its inputs. the power of the',\n",
       " 'system emerges from the combination of many units in an',\n",
       " 'appropriate way. a network is utilized different function by',\n",
       " 'connecting weights. complex functions can be implemented',\n",
       " 'by connecting the units together with appro priate weights. it',\n",
       " 'has been shown that a sufficiently large network with an',\n",
       " 'appropriate structure and property chosen weights can',\n",
       " 'approximate with arbitrary accuracy any function satisfy ing',\n",
       " 'certain broad constraints. [1 ] this model is a drastically',\n",
       " 'simplif ied approximation of real nervous systems. the',\n",
       " 'which performs two functions, namely, aggregation of its',\n",
       " 'generation of an output from the aggregated inputs.',\n",
       " 'through this simple structure, neural networks have been',\n",
       " 'shown to be able to approximate most continuous functions',\n",
       " 'to any degree of accuracy, by choice of an appropriate',\n",
       " 'number of neuron units (kurban and yildirim, 2003;',\n",
       " 'yildirim and uzmay, 2003) . [2]',\n",
       " 'human brain is made up of a network of neurons that are',\n",
       " 'coupled with receptors and effectors. receptors are called',\n",
       " '“dendrites” and effectors are called “axons” .[3] fig. 1',\n",
       " 'shows that the dendrites collects the signals from many',\n",
       " 'other neuron s in a limited area; a cell body  or soma that',\n",
       " 'along branching axon that distributes the response through',\n",
       " 'contacts with dendrite trees  of many other neurons. [4]',\n",
       " 'anns  are basically massive parallel computational',\n",
       " 'models that imitate the function of human brain. an ann',\n",
       " 'consists of large number of simple processors linked by',\n",
       " 'weighted connections. by analogy, the processing nodes',\n",
       " 'may be called “neurons”.  each node output depends only on',\n",
       " 'the information that is locally available at the node, either',\n",
       " 'stored internally or arriving via the weighted connections.',\n",
       " 'each unit receives inputs from many other nodes transmits',\n",
       " 'element is not very powerful; it generates a scalar output',\n",
       " 'with single numerical value, which is a simple non -linear',\n",
       " 'function of its inputs. the power of the system emerges from the combination of many units in an appropriate way.',\n",
       " '[1] the ann does not really solve the problem in a strictly',\n",
       " 'mathematical sense, but it demonstrates information',\n",
       " 'processing characteristics that give an approximate solution',\n",
       " 'to a given problem. the anns have been widely used in',\n",
       " 'complex non linear function mapp ing, image processing,',\n",
       " 'pattern recogni tion & classification & so on. feed -forward',\n",
       " 'networks are common type of neural networks. a feed',\n",
       " 'forward network comprises an input layer, where the inputs',\n",
       " 'of the problem are received, hidden layers, where the',\n",
       " 'relations hip between the inputs & outputs are determined &',\n",
       " 'represented by synaptic weights, & an output layer which',\n",
       " 'emits the outputs of the problem. the neural feed forward',\n",
       " 'network is modeled with three basic elements:  a) a set of',\n",
       " 'synapses characterized by synapti c weights,  b) an adder or',\n",
       " 'linear combiner for summing the input signals.  c) an',\n",
       " 'activation function for limiting the amplitude of the output',\n",
       " 'of neuron to some finite value. the input of the activation',\n",
       " 'function can be increased by using a bias term. here, we',\n",
       " 'have made use of a certain ann architecture known as the',\n",
       " 'multi -layer -feed-forward neural network or multi layer',\n",
       " 'perceptron (mlp) [5] .',\n",
       " 'and a corresponding desire d or target response set at the',\n",
       " 'output (when this is the case the training is called',\n",
       " 'supervised). an error is composed from the difference',\n",
       " 'between the desired response and the system output. this',\n",
       " 'error information is fed back to the system and adjusts the',\n",
       " 'system parameters in a systematic fashion (the learning',\n",
       " 'rule). the process is repeated until the performance is',\n",
       " 'performance hinges heavily on the data. if one does not',\n",
       " 'have data that cover a significan t portion of the operating',\n",
       " 'conditions or if they are noisy, then neural network',\n",
       " 'technology is probably not the right solution. on the other',\n",
       " 'hand, if there is plenty of data and the problem is poorly',\n",
       " 'understood to derive an approximate model, then neural',\n",
       " 'network technology is a good choice. this operating',\n",
       " 'procedure should be contrasted with the traditional',\n",
       " 'engineering design, made of exhaustive subsystem',\n",
       " 'specifications and intercommunication protocols. in artificial neural networks, the desig ner chooses the network',\n",
       " 'topology, the performance function, the learning rule, and',\n",
       " 'the criterion to stop the training phase, but the system',\n",
       " 'automatically adjusts the parameters. so, it is difficult to',\n",
       " 'bring a priori information into the design, and when the',\n",
       " 'system does no t work properly it is also hard to',\n",
       " 'are extremely efficient in terms of development time and',\n",
       " 'resources, and in many difficult problems artificial neural',\n",
       " 'networks provide performance that is difficul t to match with',\n",
       " 'other technologies. denker 10 years ago said that \"artificial',\n",
       " 'neural networks are the second best way to implement a',\n",
       " 'solution\" motivated by the simplicity of their design and',\n",
       " 'because of their universality, only shadowed by the',\n",
       " 'traditional d esign obtained by studying the physics of the',\n",
       " 'as the technology of choice for many applications, such as',\n",
       " 'pattern recognition, prediction, system identification, and',\n",
       " 'biological terminology  ann terminology',\n",
       " 'neuron  node/unit/cell/neurode',\n",
       " 'synapse  connection/edge/link',\n",
       " 'synaptic efficiency  connection strength/weight',\n",
       " 'firing frequency  node output',\n",
       " 'when creating a functional model of t he biological',\n",
       " 'neuron, there are three basic components of importance.',\n",
       " 'first, the synapses of the neuron are modeled as weights.',\n",
       " 'the strength of the connection between an input and a',\n",
       " 'neuron is noted by the value of the weight. negative weight',\n",
       " 'designate excitatory connections [haykin]. the next two',\n",
       " 'components model the actual activity within the neuron cell.',\n",
       " 'an adder sums up all the inputs modified by their respective',\n",
       " 'finally, an activation function controls the amplitude of the',\n",
       " 'output of the neuron. an acceptable range of output is',\n",
       " 'usually between 0 and 1, or -1 and 1.  mathematically, this',\n",
       " 'process is described in the figure,',\n",
       " 'from this model the interval activity of the neuron can be',\n",
       " 'shown to be,',\n",
       " 'the output of the neuron, yk, would therefore be the',\n",
       " 'outcome of some activation function on the value of vk. [ 7]',\n",
       " 'this is a subclass of acrylic networks in which a',\n",
       " 'connection is allowed from a node in layer i only to nodes',\n",
       " 'succinctly described by a sequence of numbers indicating',\n",
       " 'the number of nodes in each layer. for instance, the network shown in fig. 4 is a 3 -2-3-2 feed forward network;',\n",
       " 'nodes in the first hidden layer (layer 1), three nodes in the',\n",
       " 'second hidden layer (layer 2), and two nodes in  the output',\n",
       " 'layer (layer 3).  these networks, generally with no more',\n",
       " 'than four such layers, are among the most common neural',\n",
       " 'nets in use, so much so that some users identify the phrase',\n",
       " '“neural networks” to mean only feed forward networks.',\n",
       " 'conceptually, node s in successively higher layers abstract',\n",
       " 'successively higher level features from preceding layers. in',\n",
       " 'the literature on neural networks, the term “feed forward”',\n",
       " 'has been used sometimes to refer to layered or acrylic',\n",
       " 'brain are “hard wired.” it is equally obvious that animals,',\n",
       " 'especially the higher order animals, learn as they grow.',\n",
       " 'how does this learning occur? what are possible',\n",
       " 'mathematical models of learning?  in this section, we',\n",
       " 'summarize some of the basic theories of biological learning',\n",
       " 'and their adaptations for artificial neural networks. in',\n",
       " 'artificial neural networks, learning refers to the method of',\n",
       " 'modifying the weights of c onnections between the nodes of',\n",
       " 'a specified network.  learning is the process by which the',\n",
       " 'random -valued parameters (weights and bias) of a neural',\n",
       " 'network are adapted through a continuous process of',\n",
       " 'simulation by the environment in which network is',\n",
       " 'embedded . learning rate is defined as the rate at which',\n",
       " 'network gets adapted. type of learning is determined by the',\n",
       " 'manner in which parameter change takes place. learning',\n",
       " 'may be categorized as supervised learning, unsupervised',\n",
       " 'learning and r einforced learning.  in supervised learning,  a',\n",
       " 'teacher is available to indicate whether a system is',\n",
       " 'performing correctly, or to indicate a desired response, or to',\n",
       " 'available and learning must rely on guidance obtained',\n",
       " 'heuristically by the system examining different sample data',\n",
       " 'or the environment. learning is similar to training i.e. one',\n",
       " 'has to learn somethi ng which is analogous to one has to be',\n",
       " \"application of a set of inputs produces (either 'direct' or via\",\n",
       " 'a relaxation process) the desired set of outputs. various',\n",
       " 'methods to set the strengths of th e connections exist. one',\n",
       " 'way is to set the weights explicitly, using a priori',\n",
       " 'feeding it teaching patterns and letting it change its weights',\n",
       " 'according to some learning rule. we  can categorize the',\n",
       " 'learning situations in two distinct sorts. these are',\n",
       " 'supervised learning  or associative learning in which the',\n",
       " 'network is trained by providing it with input and matching',\n",
       " 'output patterns. these input -output pairs can be provided by',\n",
       " 'an external teacher, or by the system which contains the',\n",
       " 'neural network (self -supervised).  example:  an',\n",
       " 'archaeologist discovers a human skeleton and has to',\n",
       " 'determine whether it belonged to man or woman. in doing',\n",
       " 'this, the archaeologist is guided by many past ex amples of',\n",
       " 'male and female skeletons. examination of these past',\n",
       " 'examples (called the training set) allows the archaeologist',\n",
       " 'to learn about the distinctions between male and female',\n",
       " 'learning, and th e result of learning process can be applied to',\n",
       " 'determine whether the newly discovered skeleton belongs to',\n",
       " 'man or woman.',\n",
       " 'unsupervised learning  or self -organization in which an',\n",
       " '(output) unit is trained to  respond to clusters of pattern',\n",
       " 'within the input. in this paradigm the system is supposed to',\n",
       " 'discover statistically salient features of the input population.',\n",
       " 'unlike the supervised learning paradigm, there is no a priori',\n",
       " 'set of categories into which the pat terns are to be classified;',\n",
       " 'rather the system must develop its own representation of the',\n",
       " 'archaeologist has to determine whether a set of skeleton',\n",
       " 'fragments belong to the same dinosaur species or need to  be',\n",
       " 'differentiated into different species. for this task, no',\n",
       " 'previous data may be available to clearly identify the',\n",
       " 'species for each skeleton fragment. the archaeologist has to',\n",
       " 'determine whether the skeletons (that can be reconstructed',\n",
       " 'from the fragments) are sufficiently similar to belong to the',\n",
       " 'same species, or if the differences between these skeletons',\n",
       " 'are large enough to warrant grouping them into different',\n",
       " 'the skeletons. one archaeologist may believe the skeletons',\n",
       " 'belong to different species, while another may disagree, and',\n",
       " 'there is no absolute criterion to determine who is correct.',\n",
       " 'reinforcement learning  is type of learning may be',\n",
       " 'considered as an intermediate form of the above two types',\n",
       " 'of learning. here the learning machine does some action on',\n",
       " 'the environment and gets a feedback response from the',\n",
       " '(rewarding ) or bad (punishable) based on the environmental',\n",
       " 'response and accordingly adjusts its parameters. generally,',\n",
       " 'parameter adjustment is continued until an equilibrium state',\n",
       " 'occurs, following which there will be       no more changes',\n",
       " 'be categorized under this type of learning. [ 7]',\n",
       " 'the back propagation algorithm (rumelhart and',\n",
       " 'mcclelland, 1986) is used in  layered feed -forward anns.',\n",
       " 'this means that the artificial neurons are  organized in',\n",
       " 'layers,  and send their signals “forward”, and then the errors',\n",
       " 'are propagated backwards. the network receives inputs by',\n",
       " 'neurons in the input layer , and the output of the network is',\n",
       " 'given  by the neurons on an output layer . there may be one',\n",
       " 'or m ore intermediate hidden layers . the back propagation',\n",
       " 'algorithm uses supervised learning, which means that we',\n",
       " 'provide the  algorithm with examples of the inputs and',\n",
       " 'outputs we want the network to compute, and  then the error',\n",
       " '(difference between actual and exp ected results) is',\n",
       " 'reduce this error, until the ann learns the training  data.',\n",
       " 'the training begins with random weights, and the goal is to',\n",
       " 'adjust them so that the  error will be minimal.  [9] back',\n",
       " 'propagation network has gained importance due to the',\n",
       " 'shortcomings of other available networks. the network is a',\n",
       " 'multi layer network (multi layer perception) that contains at',\n",
       " 'least one hidden layer in addition to input and output layers.',\n",
       " 'number of hidden laye rs & numbers of neurons in each',\n",
       " 'hidden layer is to be fixed based on application, the',\n",
       " 'complexity of the problem and the number of inputs and',\n",
       " 'enables the network to simulate non -linearity in practical',\n",
       " 'propagation network is chosen for present work.  [3]',\n",
       " 'phase is called testing. training, in bac k propagation is',\n",
       " 'based on gradient decent rule that tends to adjust weights',\n",
       " 'and reduce system error in the network. input layer has',\n",
       " 'neurons equal in number to that of the inputs. similarly,',\n",
       " 'output layer neurons are same in the number as number of',\n",
       " 'and error method using the experimental data. [ 10]',\n",
       " 'developed, using the neural network toolbox of mat lab.',\n",
       " 'different anns are build rather than using one large ann',\n",
       " 'better adjustment of the ann for each specific problem,',\n",
       " 'one of the most relevant aspects of a neural network is',\n",
       " 'during neural network training is called over fitting. the',\n",
       " 'error on the training set is driven to a very small value, but',\n",
       " 'when new data is presented to the network, the error is',\n",
       " 'but it has not learned to generalize to new situations. one',\n",
       " 'method for improving net work generalization is to use a',\n",
       " 'network that is just large enough to provide an adequate fit.',\n",
       " 'the larger network you use the more complex functions the',\n",
       " 'network can create. there are two other methods for',\n",
       " 'neural network toolbox software: regularization & early',\n",
       " 'training feed forward neural networks is the mean sum o f',\n",
       " 'squares of the network errors,',\n",
       " 'performance function by adding a term that consists of the',\n",
       " 'mean of the sum of the squares of the network weights &',\n",
       " 'msereg = λmse +(1 -λ)msw,                                       (3)',\n",
       " 'where λ  is the performance ratio, &',\n",
       " 'using this performance function causes the network to have',\n",
       " 'smaller weights & biases, & this force t he network response',\n",
       " 'to be smoother & less likely to over fit.  once the different',\n",
       " 'stages of the training process & the ann structure had been',\n",
       " 'determined, & before the optimization procedure is',\n",
       " 'developed, it is important to estimate the ann prediction',\n",
       " 'qualit ies. there is excellent agreement of predicted values',\n",
       " '& expected values. this close agreement shows that the',\n",
       " 'ann can be used in the data analysis, of theoretical work to',\n",
       " 'generate the missing data in the theoretical program. the',\n",
       " 'results of model ann are com pared with the hydrodynamic',\n",
       " 'simulation data. [ 6]',\n",
       " 'the artificial neural network can be used for prediction',\n",
       " 'of pressure distribution in hydrodynamic journal bearing',\n",
       " 'which can be further used for stability analysis of',\n",
       " 'hydrodynamic journal bearing.  [11].',\n",
       " 'as the ann is an emerging technology it can be used for',\n",
       " 'data analysis in applications such as pattern recognition,',\n",
       " 'prediction, system identification & control. from above',\n",
       " 'theories it can be seen that ann i s a radial basis function back propagation network. the network is capable of',\n",
       " 'predicting the parameters by experimental system. the',\n",
       " 'network has parallel structure and fast learning capacity.',\n",
       " 'the collected experimental data such as speed, load, &',\n",
       " 'training and testing data for an artificial neural network.',\n",
       " 'the neural network is a feed forward three layered network.',\n",
       " 'quick propagation algorithm is used to update the weight of',\n",
       " 'the network during the train ing. the ann has a superior',\n",
       " 'performance to follow the desired results of the system and']"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_list = filter_sentences(text_list)\n",
    "print('Number of sentences:', len(text_list), end='\\n\\n')\n",
    "text_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_patterns(txt):\n",
    "    patterns = [\n",
    "        r'in\\sfig\\.\\s\\d',\n",
    "        r'fig\\.\\s\\d',\n",
    "        r'\\s?\\[\\s?\\d\\s?]\\s?',\n",
    "    ]\n",
    "    for pattern in patterns:\n",
    "        txt = re.sub(pattern, '', txt)\n",
    "\n",
    "    return txt\n",
    "\n",
    "def replace_patterns_in_sentences(sentences):\n",
    "    new_sentences = []\n",
    "    for sentence in sentences:\n",
    "        new_sentence = replace_patterns(sentence)\n",
    "        new_sentences.append(new_sentence)\n",
    "    return new_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abstract : - this paper presents an emergence of an artificial',\n",
       " 'neural network (ann) as a tool for analysis of different',\n",
       " 'parameters of a system. an artificial neural network (ann) is',\n",
       " 'an information -processing paradigm that is inspired by the way',\n",
       " 'biological nervous systems such as brain, process information.',\n",
       " 'ann consists of multiple layers of simple processing elements',\n",
       " 'called as neurons. the neuron performs two functions, namel y,',\n",
       " 'collection of inputs & generation of an output. use of ann',\n",
       " 'provides overview of the theory, learning rules, and applications',\n",
       " 'of the most important neural network models, definitions and',\n",
       " 'style of computation . the mathematical model of network',\n",
       " 'throws the light on the concept of inputs, weights, summing',\n",
       " 'function, activation function & outputs. then ann helps to',\n",
       " 'decide the type of learning for  adjustment of weights with',\n",
       " 'change in parameters. finally the analysis of a system is',\n",
       " 'completed by ann implementation  & ann training & prediction',\n",
       " 'keywords:  biological inspiration,  ann methodology, ann',\n",
       " 'many tasks involving intelligence or pattern recognition',\n",
       " 'are extremely difficult to automate, but appear to be',\n",
       " 'perfor med very easily by humans. for instance, human s',\n",
       " 'recognize various objects and make sense out of the large',\n",
       " 'amount of visual information in their surroundings,',\n",
       " 'apparently requiring very little effort. it stands to reason',\n",
       " 'that computing systems that attempt s imilar tasks will profit',\n",
       " 'enormou sly from understanding how human s perform these',\n",
       " 'tasks, and simulating these processes to the extent allowed',\n",
       " 'by physical limitations. this necessitates the study and',\n",
       " 'simulation of neural networks.  the neural network of an',\n",
       " 'human is part of its nervous system, containing a large',\n",
       " 'number of interconnected neurons (nerve cells). “neural” is',\n",
       " 'an adjective for neuron, and “network” denotes a graph like',\n",
       " 'systems whose central them e is borrowed from the analogy',\n",
       " 'of biological neural networks.  artificial neural networks',\n",
       " 'are also referred to as “neural nets”, artificial neural',\n",
       " 'systems “parallel distributed processing systems” and',\n",
       " '“connectionist systems”. for a computing system to be',\n",
       " 'called by these pretty names, it is necessary for the system',\n",
       " 'to have a labeled directed graph structure where nodes',\n",
       " 'perform some simple computations. from elementary graph',\n",
       " 'theory we recall that a “directed graph” consists of a set of',\n",
       " '“nodes”  (vertices) and  a set of “connections”',\n",
       " '(edges/links/arcs) connecting pairs of nodes. in a neural',\n",
       " 'network, each node performs some simple computations,',\n",
       " 'and each connection conveys a signal from one node to',\n",
       " 'another, labeled by a number called the “connection',\n",
       " 'strength” or “ weight” indicating the extent to which a',\n",
       " 'signal is amplified or diminished by connection. this',\n",
       " 'system is the alternative for human expertise and knowledge. artificial neural networks are modeled closely',\n",
       " 'following the brain and therefore a great deal of',\n",
       " 'terminology is borrowed from neuroscience.',\n",
       " 'non-linear mapping systems with a structure loosely based',\n",
       " 'on principles observed in the biological nervous systems. in',\n",
       " 'greatly simplified t erms from, a typical real neuron has a',\n",
       " 'branching dentritic tree that collects signals from many',\n",
       " 'other neurons in a limited area; a cell body that integrates',\n",
       " 'collected signals and generates a response signal (as well as',\n",
       " 'manages metabolic functions); and alo ng branching axon',\n",
       " 'that distributes the response through contacts with dentritic',\n",
       " 'trees of many other neurons. the response of each neuron is',\n",
       " 'a relatively simple non -linear function of its inputs and is',\n",
       " 'largely determined by the strengths of the connections from',\n",
       " 'units, systems containing many neurons can generate',\n",
       " 'complex and intersecting behaviors. in general terms, a nn',\n",
       " 'consists of large number of simple processors linked by',\n",
       " 'weighted connectio ns. by analogy, the processing nodes',\n",
       " 'may be called “neurons”. each node output depends only on',\n",
       " 'the information that is locally available at the node, either',\n",
       " 'stored internally or arriving via the weighted connections.',\n",
       " 'each unit receives inputs from many oth er nodes and',\n",
       " 'transmits its output to other nodes. by itself, a single',\n",
       " 'processing element is not very powerful; it generates a',\n",
       " 'scalar output with a single numerical value, which is a',\n",
       " 'simple non -linear function of its inputs. the power of the',\n",
       " 'system emerges from the combination of many units in an',\n",
       " 'appropriate way. a network is utilized different function by',\n",
       " 'connecting weights. complex functions can be implemented',\n",
       " 'by connecting the units together with appro priate weights. it',\n",
       " 'has been shown that a sufficiently large network with an',\n",
       " 'appropriate structure and property chosen weights can',\n",
       " 'approximate with arbitrary accuracy any function satisfy ing',\n",
       " 'certain broad constraints.this model is a drastically',\n",
       " 'simplif ied approximation of real nervous systems. the',\n",
       " 'which performs two functions, namely, aggregation of its',\n",
       " 'generation of an output from the aggregated inputs.',\n",
       " 'through this simple structure, neural networks have been',\n",
       " 'shown to be able to approximate most continuous functions',\n",
       " 'to any degree of accuracy, by choice of an appropriate',\n",
       " 'number of neuron units (kurban and yildirim, 2003;',\n",
       " 'yildirim and uzmay, 2003) .',\n",
       " 'human brain is made up of a network of neurons that are',\n",
       " 'coupled with receptors and effectors. receptors are called',\n",
       " '“dendrites” and effectors are called “axons” .',\n",
       " 'shows that the dendrites collects the signals from many',\n",
       " 'other neuron s in a limited area; a cell body  or soma that',\n",
       " 'along branching axon that distributes the response through',\n",
       " 'contacts with dendrite trees  of many other neurons.',\n",
       " 'anns  are basically massive parallel computational',\n",
       " 'models that imitate the function of human brain. an ann',\n",
       " 'consists of large number of simple processors linked by',\n",
       " 'weighted connections. by analogy, the processing nodes',\n",
       " 'may be called “neurons”.  each node output depends only on',\n",
       " 'the information that is locally available at the node, either',\n",
       " 'stored internally or arriving via the weighted connections.',\n",
       " 'each unit receives inputs from many other nodes transmits',\n",
       " 'element is not very powerful; it generates a scalar output',\n",
       " 'with single numerical value, which is a simple non -linear',\n",
       " 'function of its inputs. the power of the system emerges from the combination of many units in an appropriate way.',\n",
       " 'the ann does not really solve the problem in a strictly',\n",
       " 'mathematical sense, but it demonstrates information',\n",
       " 'processing characteristics that give an approximate solution',\n",
       " 'to a given problem. the anns have been widely used in',\n",
       " 'complex non linear function mapp ing, image processing,',\n",
       " 'pattern recogni tion & classification & so on. feed -forward',\n",
       " 'networks are common type of neural networks. a feed',\n",
       " 'forward network comprises an input layer, where the inputs',\n",
       " 'of the problem are received, hidden layers, where the',\n",
       " 'relations hip between the inputs & outputs are determined &',\n",
       " 'represented by synaptic weights, & an output layer which',\n",
       " 'emits the outputs of the problem. the neural feed forward',\n",
       " 'network is modeled with three basic elements:  a) a set of',\n",
       " 'synapses characterized by synapti c weights,  b) an adder or',\n",
       " 'linear combiner for summing the input signals.  c) an',\n",
       " 'activation function for limiting the amplitude of the output',\n",
       " 'of neuron to some finite value. the input of the activation',\n",
       " 'function can be increased by using a bias term. here, we',\n",
       " 'have made use of a certain ann architecture known as the',\n",
       " 'multi -layer -feed-forward neural network or multi layer',\n",
       " 'perceptron (mlp).',\n",
       " 'and a corresponding desire d or target response set at the',\n",
       " 'output (when this is the case the training is called',\n",
       " 'supervised). an error is composed from the difference',\n",
       " 'between the desired response and the system output. this',\n",
       " 'error information is fed back to the system and adjusts the',\n",
       " 'system parameters in a systematic fashion (the learning',\n",
       " 'rule). the process is repeated until the performance is',\n",
       " 'performance hinges heavily on the data. if one does not',\n",
       " 'have data that cover a significan t portion of the operating',\n",
       " 'conditions or if they are noisy, then neural network',\n",
       " 'technology is probably not the right solution. on the other',\n",
       " 'hand, if there is plenty of data and the problem is poorly',\n",
       " 'understood to derive an approximate model, then neural',\n",
       " 'network technology is a good choice. this operating',\n",
       " 'procedure should be contrasted with the traditional',\n",
       " 'engineering design, made of exhaustive subsystem',\n",
       " 'specifications and intercommunication protocols. in artificial neural networks, the desig ner chooses the network',\n",
       " 'topology, the performance function, the learning rule, and',\n",
       " 'the criterion to stop the training phase, but the system',\n",
       " 'automatically adjusts the parameters. so, it is difficult to',\n",
       " 'bring a priori information into the design, and when the',\n",
       " 'system does no t work properly it is also hard to',\n",
       " 'are extremely efficient in terms of development time and',\n",
       " 'resources, and in many difficult problems artificial neural',\n",
       " 'networks provide performance that is difficul t to match with',\n",
       " 'other technologies. denker 10 years ago said that \"artificial',\n",
       " 'neural networks are the second best way to implement a',\n",
       " 'solution\" motivated by the simplicity of their design and',\n",
       " 'because of their universality, only shadowed by the',\n",
       " 'traditional d esign obtained by studying the physics of the',\n",
       " 'as the technology of choice for many applications, such as',\n",
       " 'pattern recognition, prediction, system identification, and',\n",
       " 'biological terminology  ann terminology',\n",
       " 'neuron  node/unit/cell/neurode',\n",
       " 'synapse  connection/edge/link',\n",
       " 'synaptic efficiency  connection strength/weight',\n",
       " 'firing frequency  node output',\n",
       " 'when creating a functional model of t he biological',\n",
       " 'neuron, there are three basic components of importance.',\n",
       " 'first, the synapses of the neuron are modeled as weights.',\n",
       " 'the strength of the connection between an input and a',\n",
       " 'neuron is noted by the value of the weight. negative weight',\n",
       " 'designate excitatory connections [haykin]. the next two',\n",
       " 'components model the actual activity within the neuron cell.',\n",
       " 'an adder sums up all the inputs modified by their respective',\n",
       " 'finally, an activation function controls the amplitude of the',\n",
       " 'output of the neuron. an acceptable range of output is',\n",
       " 'usually between 0 and 1, or -1 and 1.  mathematically, this',\n",
       " 'process is described in the figure,',\n",
       " 'from this model the interval activity of the neuron can be',\n",
       " 'shown to be,',\n",
       " 'the output of the neuron, yk, would therefore be the',\n",
       " 'outcome of some activation function on the value of vk.',\n",
       " 'this is a subclass of acrylic networks in which a',\n",
       " 'connection is allowed from a node in layer i only to nodes',\n",
       " 'succinctly described by a sequence of numbers indicating',\n",
       " 'the number of nodes in each layer. for instance, the network shown  is a 3 -2-3-2 feed forward network;',\n",
       " 'nodes in the first hidden layer (layer 1), three nodes in the',\n",
       " 'second hidden layer (layer 2), and two nodes in  the output',\n",
       " 'layer (layer 3).  these networks, generally with no more',\n",
       " 'than four such layers, are among the most common neural',\n",
       " 'nets in use, so much so that some users identify the phrase',\n",
       " '“neural networks” to mean only feed forward networks.',\n",
       " 'conceptually, node s in successively higher layers abstract',\n",
       " 'successively higher level features from preceding layers. in',\n",
       " 'the literature on neural networks, the term “feed forward”',\n",
       " 'has been used sometimes to refer to layered or acrylic',\n",
       " 'brain are “hard wired.” it is equally obvious that animals,',\n",
       " 'especially the higher order animals, learn as they grow.',\n",
       " 'how does this learning occur? what are possible',\n",
       " 'mathematical models of learning?  in this section, we',\n",
       " 'summarize some of the basic theories of biological learning',\n",
       " 'and their adaptations for artificial neural networks. in',\n",
       " 'artificial neural networks, learning refers to the method of',\n",
       " 'modifying the weights of c onnections between the nodes of',\n",
       " 'a specified network.  learning is the process by which the',\n",
       " 'random -valued parameters (weights and bias) of a neural',\n",
       " 'network are adapted through a continuous process of',\n",
       " 'simulation by the environment in which network is',\n",
       " 'embedded . learning rate is defined as the rate at which',\n",
       " 'network gets adapted. type of learning is determined by the',\n",
       " 'manner in which parameter change takes place. learning',\n",
       " 'may be categorized as supervised learning, unsupervised',\n",
       " 'learning and r einforced learning.  in supervised learning,  a',\n",
       " 'teacher is available to indicate whether a system is',\n",
       " 'performing correctly, or to indicate a desired response, or to',\n",
       " 'available and learning must rely on guidance obtained',\n",
       " 'heuristically by the system examining different sample data',\n",
       " 'or the environment. learning is similar to training i.e. one',\n",
       " 'has to learn somethi ng which is analogous to one has to be',\n",
       " \"application of a set of inputs produces (either 'direct' or via\",\n",
       " 'a relaxation process) the desired set of outputs. various',\n",
       " 'methods to set the strengths of th e connections exist. one',\n",
       " 'way is to set the weights explicitly, using a priori',\n",
       " 'feeding it teaching patterns and letting it change its weights',\n",
       " 'according to some learning rule. we  can categorize the',\n",
       " 'learning situations in two distinct sorts. these are',\n",
       " 'supervised learning  or associative learning in which the',\n",
       " 'network is trained by providing it with input and matching',\n",
       " 'output patterns. these input -output pairs can be provided by',\n",
       " 'an external teacher, or by the system which contains the',\n",
       " 'neural network (self -supervised).  example:  an',\n",
       " 'archaeologist discovers a human skeleton and has to',\n",
       " 'determine whether it belonged to man or woman. in doing',\n",
       " 'this, the archaeologist is guided by many past ex amples of',\n",
       " 'male and female skeletons. examination of these past',\n",
       " 'examples (called the training set) allows the archaeologist',\n",
       " 'to learn about the distinctions between male and female',\n",
       " 'learning, and th e result of learning process can be applied to',\n",
       " 'determine whether the newly discovered skeleton belongs to',\n",
       " 'man or woman.',\n",
       " 'unsupervised learning  or self -organization in which an',\n",
       " '(output) unit is trained to  respond to clusters of pattern',\n",
       " 'within the input. in this paradigm the system is supposed to',\n",
       " 'discover statistically salient features of the input population.',\n",
       " 'unlike the supervised learning paradigm, there is no a priori',\n",
       " 'set of categories into which the pat terns are to be classified;',\n",
       " 'rather the system must develop its own representation of the',\n",
       " 'archaeologist has to determine whether a set of skeleton',\n",
       " 'fragments belong to the same dinosaur species or need to  be',\n",
       " 'differentiated into different species. for this task, no',\n",
       " 'previous data may be available to clearly identify the',\n",
       " 'species for each skeleton fragment. the archaeologist has to',\n",
       " 'determine whether the skeletons (that can be reconstructed',\n",
       " 'from the fragments) are sufficiently similar to belong to the',\n",
       " 'same species, or if the differences between these skeletons',\n",
       " 'are large enough to warrant grouping them into different',\n",
       " 'the skeletons. one archaeologist may believe the skeletons',\n",
       " 'belong to different species, while another may disagree, and',\n",
       " 'there is no absolute criterion to determine who is correct.',\n",
       " 'reinforcement learning  is type of learning may be',\n",
       " 'considered as an intermediate form of the above two types',\n",
       " 'of learning. here the learning machine does some action on',\n",
       " 'the environment and gets a feedback response from the',\n",
       " '(rewarding ) or bad (punishable) based on the environmental',\n",
       " 'response and accordingly adjusts its parameters. generally,',\n",
       " 'parameter adjustment is continued until an equilibrium state',\n",
       " 'occurs, following which there will be       no more changes',\n",
       " 'be categorized under this type of learning.',\n",
       " 'the back propagation algorithm (rumelhart and',\n",
       " 'mcclelland, 1986) is used in  layered feed -forward anns.',\n",
       " 'this means that the artificial neurons are  organized in',\n",
       " 'layers,  and send their signals “forward”, and then the errors',\n",
       " 'are propagated backwards. the network receives inputs by',\n",
       " 'neurons in the input layer , and the output of the network is',\n",
       " 'given  by the neurons on an output layer . there may be one',\n",
       " 'or m ore intermediate hidden layers . the back propagation',\n",
       " 'algorithm uses supervised learning, which means that we',\n",
       " 'provide the  algorithm with examples of the inputs and',\n",
       " 'outputs we want the network to compute, and  then the error',\n",
       " '(difference between actual and exp ected results) is',\n",
       " 'reduce this error, until the ann learns the training  data.',\n",
       " 'the training begins with random weights, and the goal is to',\n",
       " 'adjust them so that the  error will be minimal. back',\n",
       " 'propagation network has gained importance due to the',\n",
       " 'shortcomings of other available networks. the network is a',\n",
       " 'multi layer network (multi layer perception) that contains at',\n",
       " 'least one hidden layer in addition to input and output layers.',\n",
       " 'number of hidden laye rs & numbers of neurons in each',\n",
       " 'hidden layer is to be fixed based on application, the',\n",
       " 'complexity of the problem and the number of inputs and',\n",
       " 'enables the network to simulate non -linearity in practical',\n",
       " 'propagation network is chosen for present work. ',\n",
       " 'phase is called testing. training, in bac k propagation is',\n",
       " 'based on gradient decent rule that tends to adjust weights',\n",
       " 'and reduce system error in the network. input layer has',\n",
       " 'neurons equal in number to that of the inputs. similarly,',\n",
       " 'output layer neurons are same in the number as number of',\n",
       " 'and error method using the experimental data. [ 10]',\n",
       " 'developed, using the neural network toolbox of mat lab.',\n",
       " 'different anns are build rather than using one large ann',\n",
       " 'better adjustment of the ann for each specific problem,',\n",
       " 'one of the most relevant aspects of a neural network is',\n",
       " 'during neural network training is called over fitting. the',\n",
       " 'error on the training set is driven to a very small value, but',\n",
       " 'when new data is presented to the network, the error is',\n",
       " 'but it has not learned to generalize to new situations. one',\n",
       " 'method for improving net work generalization is to use a',\n",
       " 'network that is just large enough to provide an adequate fit.',\n",
       " 'the larger network you use the more complex functions the',\n",
       " 'network can create. there are two other methods for',\n",
       " 'neural network toolbox software: regularization & early',\n",
       " 'training feed forward neural networks is the mean sum o f',\n",
       " 'squares of the network errors,',\n",
       " 'performance function by adding a term that consists of the',\n",
       " 'mean of the sum of the squares of the network weights &',\n",
       " 'msereg = λmse +(1 -λ)msw,                                       (3)',\n",
       " 'where λ  is the performance ratio, &',\n",
       " 'using this performance function causes the network to have',\n",
       " 'smaller weights & biases, & this force t he network response',\n",
       " 'to be smoother & less likely to over fit.  once the different',\n",
       " 'stages of the training process & the ann structure had been',\n",
       " 'determined, & before the optimization procedure is',\n",
       " 'developed, it is important to estimate the ann prediction',\n",
       " 'qualit ies. there is excellent agreement of predicted values',\n",
       " '& expected values. this close agreement shows that the',\n",
       " 'ann can be used in the data analysis, of theoretical work to',\n",
       " 'generate the missing data in the theoretical program. the',\n",
       " 'results of model ann are com pared with the hydrodynamic',\n",
       " 'simulation data.',\n",
       " 'the artificial neural network can be used for prediction',\n",
       " 'of pressure distribution in hydrodynamic journal bearing',\n",
       " 'which can be further used for stability analysis of',\n",
       " 'hydrodynamic journal bearing.  [11].',\n",
       " 'as the ann is an emerging technology it can be used for',\n",
       " 'data analysis in applications such as pattern recognition,',\n",
       " 'prediction, system identification & control. from above',\n",
       " 'theories it can be seen that ann i s a radial basis function back propagation network. the network is capable of',\n",
       " 'predicting the parameters by experimental system. the',\n",
       " 'network has parallel structure and fast learning capacity.',\n",
       " 'the collected experimental data such as speed, load, &',\n",
       " 'training and testing data for an artificial neural network.',\n",
       " 'the neural network is a feed forward three layered network.',\n",
       " 'quick propagation algorithm is used to update the weight of',\n",
       " 'the network during the train ing. the ann has a superior',\n",
       " 'performance to follow the desired results of the system and']"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_list = replace_patterns_in_sentences(text_list)\n",
    "text_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LSTM-Based-Text-Genreation-JASRV2hh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
